How to troubleshoot linux servers or what are the ways to troubleshoot?

Ping the server where application is deployed.
Telnet the application url/ IP of server to check if the port is enable of not.
Ssh to the server and test the application using curl or wget with localhost and port.
Check the Harddisk space by df -h
Check the CPU utilization --> using top command
Check ram utilization --> by free command
Check the process if it's running or not by using ps -ef 
check if port is listning or not using netstat
Check the logs of your application or software.


EFK- helm:


Elastic stack

collect , process 


For  DevOps
	
	
	I would like to enhance my skills and thought to learn new things for career growth and 
	to compete with the existing IT world




AWS  
		  EC2
		  VPC-(Virtual private cloud)	
		  Subnet
		  Route table
		  Internet gateway
		  VPC peering	
		  Elastic Ips
		  NAt instance										
		  NAT gateway
		  S3 (Storage)
		  IAM		
		  Load BAlancer
          Autoscaling					
		  Route 53
		  Cloudwatch,SQS,SNS,SES
          Database
		  SSM (Patching)
		  AWS Lambda		
		  
Terraform  (Infrastructure as code)
GIT -Source Code Management Tool	
Maven - Build Artifacts
Jenkins - CI/CD
Docker  -Container Service   --H@r!$h1234  Hari@dec*2019
Kubernetes 	Orcestration tool for containers
Ansible	   - Configuration Management tool - Playbooks
Monitoring tools
   Nagios
   DataDog(EC2,Docker, Kubernetes)
   Promethus and Grafana(For Kubernetes)	

=========================



DevOps

Career RoadMap
----------

------

DevOps

1.Plan
2.Code
3.Build.
4.Deploy
5.Test
6.Release
7.Config/Operations
8.Monitoring 


Step a) 1 , 2 . Learn Programming languages
 
  Java,Python*

Step b) 3, 4 .  Learn Building Tools
		
   Build  -- Maven, Gradle
   SCM    --  Git* ,SVN ,Github*, BitBucket
   CI CD  -- Jenkins
   Container -- Docker ( Container Platform) ,Kubernetes (Container Management Platform)
   
Step c) 5. Learn how to run  tests from Command CI/CD
	  
Step d) 6. Learn cloud Service Platforms .
      
	   AWS, Azure , Google Cloud Platform
	   
Step e) 7. Learn Config Management Tools  	   
	  
	   Puppet,Chef, Ansible
	   
Step f) 8. Learn Logging/Monitoring Tools

         Nagios

----------------------------------------------------
DevOps

Programming language 
    Python
	 
Source Control
   Git Tool   -  Versioning 
   Github.com  - Repository
   
Operating Systems

   Linux
         BASH
		         Basic Linux Commands
				LS    APT/YUM
				GREP   LSOF
				UNAME  SS
				UPTIME	NETSTAT
				TOP     MOUNT
				MAN     TOP
				
				  /bin  /boot /dev  /etc /home /var /opt /proc  /mnt /sbin				  
				
         SSH				
   
Networking   

         DNS Name Resolution 
		 SUBNETTING
		 GATEWAYS
		 DHCP/NAT
		 HTTP
		 
		

    Farewalls                                 Load balancing                           Proxy Server
	
	Incoming/Outgoing                           Round Robin 							Traffic Flow
	Stateful/Non-Stateful						Weighted Round Robin                     Forward/Reverse
	Layer 3-7 Firewalls							Least Connections
  

Cloud Providers
	
     AWS    Azure**   Google Cloud
  
  
Infrastructure as Code

Containers
 
    Docker**
	
    Orchestration --	Kubernetes
	
	
Infrastructure Provisioning

    Terraform

Configuration Management
   
    Ansible** ,Puppet  Chef , Saltstack
	
	
CI/CD pipelines

   Deploy to-- 	
   
        Jenkins** ,  Gitlab , github Actions 
   
   
Log and Monitoring Management

    Nagios , ---   
 -------------------------------
 
 
  SQL
  shell  scripts /  python scripts
  
  Jenkins 5 
  
  CI/CD Pipelines
   pluggings
   
 github =
  git 
 build trigger
 
 Ansible
 
 AWS -
 
 Docker / K8s -- Container
 
 Yaml file
 
 ========================================
 
 DevOps
 

 K8s
 Docker
 Ansible
 AWS
***Jenkins ******
 Git
 Github
 Maven/npm
 Nexus
 STM/Webserver/Apache/Weblogic
 
 
 
 
 
+++++++++++++++++++

sed  - Stream editor:

sed 's/mango/apple/g'  filename 

sed  -i 's/mango/apple/g'  filename  ignore case

sed 's/mango//g'  filename 

sed '/mango/d'  filename   -- deleting line which matches mango

sed '/^$/d'  filename -- deleting empty lines

sed '1d'  filename -- deleting 1st time

sed '1,2d'  filename deleting 1st 2 time

sed 's/\t/ /g'  filename   -- replcace tabs to space

sed 's/ /\t/g'  filename   -- replcace space to tabs

sed -n 12, 18p   filename   ----- view 12 - 18 lines

sed 12,18d filename  --  to view all except 12 to 18 lines

sed G filename  - emptyline after 1 line

sed '8!s/mango/orange/g' filename    -- replace mango to orange in all lines except 8th line

sed 's/mango/orange/g' filename   -- replace mango to orange

in vi editor

:%s/mango/orange/


session 6

VPC:

10.0.0.0/24

32-24=8 
 2^8 = 256
 
 
    1 subnet  10.0.0.0/24  ---10.0.0.255/25
        
		10.0.0.0 /24
		10.0.0.1/24
		..
		10.0.0.255/25 ===> 256
		

		256 - 5 ==> 251 total 251 Ips
		
 -----------------------------------------/16  --- /28  -----
   2 subnets 256/2= 128
                         2^7 
						 32-7 =25
						 
		subnet 1 =
     		         10.0.0.0/25    ---  10.0.0.126/25
					
																		10.0.0.1/25
																		10.0.0.2/25
																		..
																		10.0.0.127/25
															
																			  128 - 5 = 123 -total IPs available for this Subnet 1	
					
        subnet 2 = 
		
		             10.0.0.128/25 -- 10.0.0.255/25
			  
																		10.0.0.128/25
																		10.0.0.129/25
																		
																		..
																		10.0.0.255/25
																		
																			   128 - 5 = 123 -total IPs available for this Subnet	2

one time maybe set subnet.
----------------------------------------------------------
VPC 
 10.0.0.0/24
 
	3  subnets 256/3 =
	
	               128 Ips 
	
	subnet 1 =
     		         10.0.0.0/25    ---  10.0.0.126/25
					
																			10.0.0.1/25
																			10.0.0.2/25
																			..
																			10.0.0.127/25
																
																		   128 - 5 = 123 -total IPs available for this Subnet 1	
						  
	subnet 2 
		
																		128/2 = 64 Ips 
																				   2^6 
																					32-6 =26

 					10.0.0.128/26	-- 10.0.0.192/26
					
																			10.0.0.129/26
																			..
																			10.0.0.192/26
																			
																			64 - 5 = Total 61 Ips
	subnet 3   64 Ips
		         10.0.0.193/26  -- 10.0.0.255/26
				 
																			 10.0.0.194/26
																			 ..
																			 10.0.0.255/26
																			 
																			64 - 5 = Total 61 Ips	
																			
																			
DHCP

Dynamic Host Configuration Protocol

Dynamically gives uniquekly Private Ips in that subnet ranges

																			
					
					
Session 7

v0.15	-Version of Terraform


terraform plan -target aws_s3_bucket.b		 #	aws_s3_bucket.b -==name of resource

	 Unique
	 
	 
	 +++++++++++++++++++++++




LINUX:	



cd
mkdir
ls
touch
rmdir
rm -rf



find . -type f -empty
find ~ -type d -empty

find . -iname harish.txt


umask
0022 -- root
0002 -- normal user

r w x
4 2 1
0777 - dir
0666 - file

chmod 
chmod -R 400 devOps

chown
chown root devOps.txt
chmod -R  root devOps


sudo su 
sudo su -

session 4:

chgrp

chgrp root devOps.txt
chgrp -R  root devOps



chown ec2-user:ec2-user devOps.txt
chown -R ec2-user:ec2-user devOps


cp

cp source destination --> file
cp -r source destination  --> directory

cp *.txt devOps


mv

mv oldname newname


file 1.txt  -------> to decide the content of file

wc

ln /var/logs/a.txt  /tmp/b.txt

ln -s logs/1.txt /tmp/b.txt

vi
vim

session 5

vi ~/.ssh/config

Host *
     ServerAliveInternal 30
	 ServerAliveCountMax 2
	 
nano test.txt

echo

cat
head
tail
sed

cat -n filename.txt
 
+++++++++++++++++++

sed  - Stream editor:

sed 's/mango/apple/g'  filename 

sed  -i 's/mango/apple/g'  filename  ignore case

sed 's/mango//g'  filename 

sed '/mango/d'  filename   -- deleting line which matches mango

sed '/^$/d'  filename -- deleting empty lines

sed '1d'  filename -- deleting 1st time

sed '1,2d'  filename deleting 1st 2 time

sed 's/\t/ /g'  filename   -- replcace tabs to space

sed 's/ /\t/g'  filename   -- replcace space to tabs

sed -n 12, 18p   filename   ----- view 12 - 18 lines

sed 12,18d filename  --  to view all except 12 to 18 lines

sed G filename  - emptyline after 1 line

sed '8!s/mango/orange/g' filename    -- replace mango to orange in all lines except 8th line

sed 's/mango/orange/g' filename   -- replace mango to orange

in vi editor

:%s/mango/orange/


less

more
sort
|
tr

grep -i harish devOps.txt

grep  harish devOps.txt 1.txt



who
who -H

last

w

uptime

lscpu

 cat /proc/cpuinfo
 
 
 users
 
 whoami
 
 whereis cat
 whereis java
 
 which ls
 
 date
 
 df -kh
 
 du -sh ~
 
 hostname
 
 hostname -i
 ifconfig
 ip a
 
 
 man
 man ls
 
 info mkdir
 
 mkdir --help
 
 
 whatis
 
 whatis mkdir
 
 
 
 service
 systemctl list-unit-files
 
 service sshd status
 systemctl status sshd
 
 
 chkconfig sshd on
 
 ps
 
ps -ef
 
kill

top

sar

zip -r  devOps.zip devOps
unzip
tar


#useradd harish
#passwd harish

chage harish

groupadd devOps

usermod -g groupname username

usermod -L username --------> lock user

usermod -U username ----->unlock

id username
groups username

usermod -aG g1 g2 g3 username


lid -g groupname

sudo su - username
sudo -iu username
 su - username
 
 visudo
   vi /etc/sudoers  
 
 userdel
 groupdel
 
 
 userdel -r username
 
 
 Crontable
 
 crontab
 
	
ssh

ssh userName@ip
or

ssh userName@hostname

with pasword
vi /etc/ssh/sshd_config
PasswordAuthentication yes

service sshd restart

scp filename userName@ip:/tmp/
or
scp filename userName@hostname:/tmp/

df -h  -- harddisk utlization 
du -sh


free -kh - ram size

mail


wget

curl -o

tee 

ls |tee  output.txt
-- display output  in console adn aslo so store in the file 

script
 
 script -a  output.txt
 exit

cal

    
    telnet
    ping
    history
    
netstat tulnpa
watch

shutdown

++++++++++++++++++++

cat /etc/shells

echo $$0
echo $SHELL
echo ps -p $$


#! /bin/bash

./filename.sh
. filename
sh filename.sh

/bin/sh
/bin/bash


sh -x filename.sh   

set -x


set +x

comments:
#

<<H

H


/*



*/



Display System defined Variables:

env
print env

comgen -v

pwd -- command

PWD -- variable name 


echo $ HISTSIZE

export HISTSIZE=200


set HISTSIZE permanent::specific user

vi ~/.bash_profile
export HISTSIZE=200



set HISTSIZE permanent::all user  run in root

vi /etc/profile
export HISTSIZE=200

echo $LOGNAME


a=10
b=10.2
c=harish
d=Tech Mahindra


sh dbbackup.sh arg1 arg2  .. args10

$0

$1   1st argument
$2
$3 
..
..
${10}

$#  number of Arguments

$*  print ALL arguments
$@  or $*
$$
$?



if [ $# -eq 2]
then
..
..

fi

String

var="Malnad College of Engineering"

echo ${#var}   -- length of the String

echo ${var:20}  

echo ${var 1:20}

echo ${var:20:14}

echo ${var:0:14}

echo ${var:-8}


Arthematic Opertaion:

expr 1 + 2
expr 2 - 3
expr 2 \* 9
expr 4 / 2

sum =`expr 1 + 2`

echo "addtion is :" `expr 2 + 3`
echo "search:" `$USER` 

-------------------------

sh commandLineArthematicOperation.sh 4 8



echo "Enter values of a is: " $1 
echo "Enter values of b is: " $2

echo "addtion of a and b :"` expr $1 + $2` 

echo "multiplication of a and b : "` expr $1 \* $2` 


--------------------------




echo "Please enter DevOps Tools.."
read -a  devopsTool

echo "entered tools are :"${devopsTool[*]}
echo "enter the position to cehck the respective value"
read n
b=`expr n - 1`
echo "entered tools  in" $n"st position:"${devopsTool[$b]}

echo "entered tools  in 1st position:"${devopsTool[0]}
echo "entered tools  in "$n"th position:"${devopsTool[`expr $n - 1`]}
# Array

--------------------------
echo " name is"
read

echo "stored in "$REPLAY
----------------------
#online printing
 
read -p "enter name:"  userName
 
read -ps "enter passsword:" passsword
echo
echo "enter username and password is " $userName $password

-----------

echo "Enter values of a"
read a 

echo "Enter values of b"
read b

echo "Enter values of a is: " $a 
echo "Enter values of b is: " $b

echo "sum  of a and b"` expr $a + $b` 

--------------------------------------

Input and Output direction symbols:

>  redirect std o/p
>> append std o/p
<  std input

0 std i/p
1 std Output
2 std error


ls > list.txt

cat < list.txt


sh hello.sh >output.log   #  0nly output in output.log file, error in console

sh hello.sh >output.log 2>&1  #both error  and output in output.log file


sh hello.sh 2>error.log 1>output.log # error in error.log , output in output.log


Control Statements:

if [ condition]
then
..
..
fi

----
if [ condition ]
then
...
...

else

fi

-----
if [ condition ] ; then
.....
.....
else
....
...
fi
-------------
a=20
b=30

if [ $a -gt $b ]
then
echo "$a is greater than $b"
else
echo "$b is greater than $c"
fi

----------------------

a=20
b=30
c=50
if [[ ($a -gt $b) && ($b -gt $c) ]]
then
echo "$a is greater than $b and $c"
elif [[ ($b -gt $c) && ($b -gt $a) ]]
echo "$b is greater than $c and $a"
else 
echo "$c is greater than $a and $b"
fi
------------------

sh search.sh

echo "enter the file name to search"
read filename
if [[ -f $filename ]]
then
echo " $filename is present in current directory"
echo "displaying the content in $filename"
cat $filename
else
echo " $filename is  not present in current directory"
echo "Do you want to create it"
echo "print yes or y or Y or Yes  ---> for creating it"
read value
if [[ $value -eq 'yes' || $value -eq 'Yes' || $value -eq 'Y' || $value -eq 'y' ]]
then
touch $filename
echo "$filname is creating.."
fi
fi

------------
if [[ -d $directory ]]


------------
if [[ -r $filename ]]

------------
if [[ -w $filename ]]

------------
if [[ -x $filename ]]

----------------------------------------
Loops

for  (( initilisation ; condition : inc/dec ))
do
..
....
..

done
-----
echo "demo of for loop"
for (( a=1;a<=5;a++ ))
do 
echo "$a"
done

echo "demo done"
----

for i in {100 .. 1}

--------------------------
while demo
initilisation
while ( condition )
do
...
....
inc/dec
done
----------------
echo "while loop demo starts"
a=5
while ( $a -ge 0 )

echo "time left "$a "Second"

a=`expr $a - 1`
done
echo "done While Demo"

----------------------

-le
-lt
-gt
-ge
-eq
------------------

switch case:

#instead of nested if else we can use switch case:
sh sonar.sh

echo "Enter option to to start ,stop ,restart"
read option

case $option in
start) 
echo "starting sonarQube"
        echo "starting......." ;;
stop) 
 echo "Stoping sonarQube"
        echo "Stoping......."
		;;
restart) 
echo "Restarting sonarQube"
        echo "Restarting......."
*)
echo "enter valid option as start or stop or restart
  usage of $0 script to start or stop or restart"
  ;;
easc

-------

sh sonar.sh start|stop|restart


case $option in
start) 
echo "starting sonarQube"
        echo "starting......." ;;
stop) 
 echo "Stoping sonarQube"
        echo "Stoping......."
		;;
restart) 
echo "Restarting sonarQube"
        echo "Restarting......."
*)
echo "enter valid option as start or stop or restart
  usage of sh $0 script to start or stop or restart"
  ;;
easc
---------------------------
convertScript.sh

 echo "enter number only as 1 to 5 "
 read number
 case $number in
 1) echo "you have typed $number is one"
 ;;
 2) echo "you have typed $number is two"
 ;;
 3) echo "you have typed $number is three"
 ;;
 4) echo "you have typed  $number is four"
 ;;
 5) echo "you have typed  $number is five"
 ;;
 *)
 echo "enter valid number from 1- 5 only"
 sh convertScript.sh
 ;;
 easc


------------------------------------------------------------

functions :

functionName(){



}

functionName


----------

sh function.sh
echo "function demo"
greeting(){
echo "Hi All,"
echo ""
echo  "
Have a nice day."
echo "
Regards,
Harish "
}

echo "callling function"

greeting

echo "called functions"
---------------------
sh utilities.sh

add()
{
echo " sum"
}

sub(){
echo "sub"
}
----------------
sh sample.sh

multi()

{ echo "multiplication"
}
-----------------
sh a.sh

source ./utilities.sh
source ./sample.sh
add
sub
echo "calling add , sub , multi functions in utilities.sh script $0 script"
------------
sh b.sh

source ./utilities.sh
source ./sample.sh
add
sub

echo "calling add , sub , multi functions in utilities.sh script in $0 script"

+++++++++++++++++++++++++++++++=



Git:

Enterprise Edition

Gitlab
Github
BitBucket(Stash)


login

username: harishkumarbr
email :harishkumarbr8@gmail.com
Password: H@r!$h1234


1: create Organization
   name of Organization: APP94815-ec-br
   email : ServiceId/Functional Mai ID
   
   https://github.com/APP94815-ec-br
2: Create a Repository

    Repository name:
	
	Public /Private 
	
https://github.com/APP94815-ec-br/Wallmart -- public repo
	

https://github.com/APP94815-ec-br/Amazon.git -- Private repo


3: Create Teams

https://github.com/orgs/APP94815-ec-br/teams/raithadinachari-teams

    Add Members to team
	Add Team to Repository
	

4: Provide the Repository access to the Team	

  	https://github.com/orgs/APP94815-ec-br/teams/raithadinachari-teams/repositories
	
	write
	read
	
	
----------
git

cd wallmart

git init

git config --global user.name ""
$ git config --global user.name "harishkumarbr"
$ git config --global user.email "harishkumarbr8@gmail.com"
git config --global --list


git status

git add .
git add filename1 filename2
git add *.java
git add *

git commit -m "some msgs"

git commit -m "some mgs" filename1 filename2


git remote add aliasname url

git remote add RD https://github.com/APP94815-ec-br/RaithaDinachari.git

git remote add origin https://github.com/APP94815-ec-br/RaithaDinachari.git



git remote -v
	

git push RD master
git push origin master

gti push origin main

PAT:

personal access token

git commit -a  -m "updated"	

git log
git log -2
git log --online


git show <commit_id>

# only file name:
git show --pretty="" --name-only <commit_id>

git remote remove aliasname  
git remote remove RD










tag:


git tag tagName

git push aliasname tagName

git tag -d tagName

stash:

git stash

git stash list

stash@{0}  -->latets
stash@{1}
stash@{2}


git stash apply
git stash apply stash@{1}

git stash drop
git stash drop stash@{1}

git stash pop
git stash pop stash@{1}


  cheery-pick:

git commit -a -m "msg1"
git commit -a -m "msg2"
git  checkout branchName

git cheery-pick <commit_id>

      Clone:


git clone <url>


git pull origin master


git fetch origin master  + git merge origin/master


ssh-keygen
.
.

##configuring public key in github


ls -la ~/.ssh

id_rsa
id_rsa.pub


cat ~/.ssh/id_rsa.pub


ssh -T git@github.com  


git@github.com:harishgowdabr/maven-web-application.git


ssh-keygen
shh-copy-id



git  API:

sshkeygenandupload.sh file by bhaskar

Branching strategy



git commit -a --aemnd -m  ""

git branch -m oldbranch newbranch

git branch -m newbranch

master>git checkout feature 

git checkout -b newbranch master



Branching

git branch

git branch branchName

git branch -d branchName

git checkout branchName

git diff branchName

git merge branchName

Merge Conflicts

git checkout -b newBranchName

git push AliasName branchName1 branchName2

git push AliasName --all

git push AliasName :branchName # branch is deleted in Remote repo

git push AliasName branchName -d


PR - Pull Request



Tags:

git tag

git tag tagName

   git tag wallmartv1.0.0

git tag -d tagName

git push AliasName --tags

git push AliasName tagName


git pull AliasName branchName 



git fetch AliasName branchName















-----------------------


Maven



Build Tools:

Maven:

Java ,JDK


javac hello.java

java hello


javac --version ------------> JDK

JRE ---

java :

java -version 

mvn -version

boot 
bin
conf - settings.xml***
lib
pom.xml

mvn clean package

wallmart.xml

mvn -f wallmart.xml  clean package



maven repo:

maven local repositories

maven central repositories

maven remote repositories

~/.m2/repository


life cycles


Life Cycle      GoalName
clean            clean:

site              site

default             validate:
					compile
					test	
					package
					install
					deploy
						


mvn clean package -Dskiptests
mvn clean package -Dmaven.test.skip=true

settings.xml

<localRepository>path</localRepository>


mvn clean package  -pl moduleName
----------------------------------------------------------

Tomcat:



Tomcat is an OS, Java Based, Web App server..


Application Servers
-------------------

1.x to 7.x --> JBoss
8.x to latest version --> Wildfly


JBoss/Wildfly --> RedHat --> IBM
Weblogic --> BEA --> Oracle
WebSphere Application Server (WAS) --> IBM


Jboss/Wildlfy --> Enterprise APp servers
bin/ :

startup.sh
shutdown.sh
startup.bat

sh catalina.sh start
sh catalina.sh stop
version.bat


conf/:

tomcat-users.xml  
server.xml-- line number 69

lib/:
jar files

logs/:

catalina.out  , manager.log ,  


webapps/:
all deployed apps,

5 default apps

work/


tmp/



--------Installation
Java 



curl -o apache-tomcat-9.0.56.zip https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.56/bin/apache-tomcat-9.0.56.zip

or

wget https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.56/bin/apache-tomcat-9.0.56.zip


unzip apache-tomcat-9.0.56.

cd /opt/apache-tomcat-9.0.56/bin


chmod u+x *.sh


ln -s /opt/apache-tomcat-9.0.56/bin/startup.sh /usr/bin/startTomcat
ln -s /opt/apache-tomcat-9.0.56/bin/shutdown.sh /usr/bin/stopTomcat





roles:

manager-gui
admin-gui
manager-script

in config
server.xml

change port line number  69



in config
tomcat-users.xml
	  <user username="admin" password="admin" roles="manager-script"/>
 <user username="admin" password="admin" roles="manager-gui,admin-gui"/



  In Webapps - Manager -- META-INF--context.xml --valve commented
         HostManager -valve commented 
		 
		 		 



Web Servers
-----------

Apache HTTP server
Nginx (Engine X)

IBM HTTP Server (IHS)

IIS




------Installation HTTP Server--

yum install httpd -y


systemctl start httpd

cd /var/www/html/

index.html


/etc/httpd/conf 
httpd.conf -- change port number	 line number 45




----------SonarQube------------------------

Open source ,Code quality Management tool

source code validation , review , coverage , analysis 


Code Review:
  Standards 
Code Coverage:
   unit test case
   
 Sonar
Java 

supports many lanaguage

 Duplicate code
 comments
 Architecture and design
	
Sonar Installation:

java 1.8
sonar 7.8

	Directories
	
	bin ,conf,logs , lib , 
	/opt/sonarqube-7.8/conf
	sonar.properties --change of port  
                   #sonar.web.port=9000

	
	/bin ---linux..
	
	sonar.sh should run in normal user
	-
	useradd sonar
	
	Give the sudo access to sonar user
visudo

sonar   ALL=(ALL)       NOPASSWD: ALL

Change the owner and group permissions to /opt/sonarqube-7.8/ directory.
chown -R sonar:sonar /opt/sonarqube-7.8/
chmod -R 775 /opt/sonarqube-7.8/

su - sonar
cd /opt/sonarqube-7.8/bin/linux-x86-64/

./sonar.sh start

	
--
administration 	--Security --Force user authentication - enable

Architecture:

Sonarqube Scanner -- Identify and reports genaration

SonarQube Server

 Compute Engine 
   its catagories below
			verneralibites
			Bugs
			Code Smells
			
  H2 -- store reports
  
  web server :
     display reports  in dashboard
	
   there is a search Engine in dashboard fot quick response 
   
   
   mvn  sonar:sonar # to run sonarqube 
   plugging:GoalName
   
   plugging extarts sonar scanner
   
   sudo su - sonar
   
   cd sonar/7.8/bin /linux
   
   sh.sonar.sh start
   if u run this in root user 
  switch to sonar user
check logs   
   /opt/sonar7.8/logs
    rm -rf /opt/sonar7.8/temp
	
cd 	opt/sonar7.8/bin/linux-x86-64/
	sh sonar.sh start
	
	Executing sonar reports:
	
	Maven - Java

pom.xml

<properties>
          SonarQube Server Details
 <sonar.host.url>http://13.234.66.155:9000/</sonar.host.url>
		<sonar.login>admin</sonar.login>
		<sonar.password>admin</sonar.password>

</properties>
	
	
	mvn clean sonar:sonar package
	
	Administration --Security--users-Token
	
	Token:
	
	7039883a8c91a3ca3ad24493e12ea32590421a12
	
	<properties>
 --- SonarQube Server Details
      <sonar.host.url>http://13.234.66.155:9000/</sonar.host.url>
		<sonar.login>7039883a8c91a3ca3ad24493e12ea32590421a12</sonar.login>
		
		
		mvn sonar:sonar
		
		
project --
Issues --
Rules--
Quality Profile-  Group of  Rules which are going to apply while executing the sonarqube report
sonar way is the default QP
Quality gates  --- collection of condition which are going to apply while executing the sonarqube report to mark as pass or 
               fail.
        
Administration -- 
    
		security  -
     		users 
		
		     users will cretaed under sonar-users group by default
		
		security  -
       		groups
						sonar-users
						sonar -administrators
						
						
		project -- to delete unknown projects
       
	   System--
              info of sonarqube 


SonarQube , Fortify 
------------
Mysql -- 3306 -port

0-----------------------------------------------------------
Nexus:
jfrog Artifactory 

SonarType Nexus
Nexus is an OSS, Java Based, Artifactory Repo.

It can be used to store the build artifacts(packages)

and retrieve the build artifcats whenever we required.		  
		
		
		java 1.8
		nexus3.36.2
		
/opt/sonatype-work/nexus3/log -- logs of nexus server
sonar.log

/opt/nexus3.36.2/etc
nexus-default.properties
   application-port=8081  -- to change port

   nexus3.36.2/bin
     nexus -------file to start nexus  server
	 
	 http://3.110.191.155:8081/
	 
	 CAN CEHCK Password HERE 
	 
	 /opt/sonatype-work/nexus3/admin.password
	 
	 admin
	 admin
	 
Server administration and configuration
  Repository
      Create Repository  (maven2 hosted - 2repo)
             version policy   --Release 
              version policy  -- Snapshot	


http://3.110.191.155:8081/repository/Walmart-release/

http://3.110.191.155:8081/repository/Walmart-snapshot/

			  
	 Nexus repo:
	 
	 In POM.xml
<distributionManagement>
	
	    <repository>
	      <id>nexus</id>
	      <name>Mithun Technologies Releases Nexus Repository</name>
	      <url>http://3.110.165.154:8081/repository/Walmart-release/</url>
	    </repository>
	    
	    <snapshotRepository>
	      <id>nexus</id>
	      <name>Mithun Technologies Snapshot Nexus Repository </name>
	      <url>http://3.110.165.154:8081/repository/Walmart-snapshot/</url>
	    </snapshotRepository>
	    
	</distributionManagement>


Nexus Credentials
-----------------
in  maven HD conf/settings.xml 

<servers>
..
...
.
.
 <server>
      <id>nexus</id>
      <username>admin</username>
      <password>admin</password>
    </server>
	


  </servers>
  
  
  mvn clean sonar:sonar deploy
  

error: if we deploy same version then we will get below error:


status: 400 Repository does not allow updating assets: Walmart-release


if we want redeploy

repositories -release  -Hosted -Deployment polices - Allow redeploy
   
-----
   Maven proxy
   
  http://3.110.165.154:8081/repository/Wallmart-Proxy-repo/
   
   maven2 proxy 
   mvn clean package
      search dependencies in maven local repo ~/.m2/repository  1st then proxy and create build .war  </target>
   and 
 it will store the dependencies in remote repo 
   mvn clean deploy
      search dependencies in maven local repo ~/.m2/repository  1st then proxy and create build .war  </target> and 
	      stores .war in remote  repo 
	     and also 
 it will store the dependencies in remote repo 
 
   
   In settings.xml
   
     <mirrors>
    <mirror>
      <id>nexus</id>
      <mirrorOf>*</mirrorOf>
      <name>Proxy repo</name>
      <url>http://3.110.165.154:8081/repository/Wallmart-Proxy-repo/</url>
 
    </mirror>
  </mirrors>

   
   In POM.XML
   
   <repositories>

  <repository>
   <id>nexus</id>
   <name>Proxy Repo</name>
   <url>http://3.110.165.154:8081/repository/Wallmart-Proxy-repo/</url>
  </repository>
  
</repositories>
   
   
   
---------
Remote Repository:

creating  remote repo for common lib to share in company 


maven2 hosted

once updated some   dependencies jar then take that tag and mention in POM.XML

<dependency>
  <groupId>com.mss</groupId>
  <artifactId>mail</artifactId>
  <version>1.0.0</version>
</dependency>


Need to configure remote repo url in POM.XML

<repositories>
			<repository>
			      <id>nexus</id>
			      <name>Remote  Repo</name>
			      <url>http://3.110.165.154:8081/repository/mss-remote-repo/</url>
			</repository>  
	</repositories>
	
	aslo
	
	change in settings.xml
	
	     <mirrors>
    <mirror>
      <id>nexus</id>
      <mirrorOf>*</mirrorOf>
      <name>Remote repo</name>
      <url>http://3.110.165.154:8081/repository/mss-remote-repo/</url>
 
    </mirror>
  </mirrors>
	-----------
	we have to give any one of them  proxy or remote repo details in POM.xml and settings.xml
	
	else we need to use  both in  in POM.xml and settings.xml
	
	maven2 group 
	
	
	Need to configure group repo url in POM.XML  and settings.xml

<repositories>
			<repository>
			      <id>nexus</id>
			      <name>Group Repo</name>
			      <url>	http://3.110.165.154:8081/repository/mss-group-repo/</url>
			</repository>  
	</repositories>
	
	aslo
	
	change in settings.xml
	
	   <mirrors>
    <mirror>
      <id>nexus</id>
      <mirrorOf>*</mirrorOf>
      <name>Group repo</name>
      <url>	http://3.110.165.154:8081/repository/mss-group-repo/</url>
    </mirror>
  </mirrors>
  
  
  
  mvn clean package   ------- build
      [INFO] Building war: /root/app/maven-web-application/target/maven-web-application.war
   
  mvn clean install - /root/.m2/repository

       Installing /root/app/maven-web-application/pom.xml to 
            /root/.m2/repository/com/mt/maven-web-application/1.0.0/maven-web-application-1.0.0.pom

 mvn clean deploy


Uploading to nexus: http://3.110.165.154:8081/repository/Walmart-release/com/mt/maven-web-application/maven-metadata.xml

 -------
 
 401
 
 credentails should same
 id , username , password
 

administration:

   Security
     
	 Privileges
	 
	  
      Roles:
	     privileges:  
		 
		  add, delete ,,..
  	    nx-admin
	     nx-anonymous
	 
	 Users:
	    
		  admin
		  anonymous
	 
     anonymous access
          enable by default   --acces repo
	
	 LDAP
	 
	 
	 
Cleanup Polices:

cleanup policies can be used to remove content from your repositories. These policies will execute at the configured frequency. 
	 

System
Task

Run 
   
  	   
	http://3.110.165.154:8081/service/rest/v1/tasks
   
   
   conf
tomcat --> server.sml

conf
sonarqube --> sonar.properties

etc
nexus --> nexus-default.properties


SQE
 2 repos
   SQE-release
   SQE-snapshot


<dimst>


remote-repo
group-repo/
proxy-repo/


\=========Jenkins


Bamboo:


Jenkins is an OS, Java Based, CI tool.


Oracle - Husdon -CI-2004 
 
 Jenkins Community  -2011
 
 CI-
 
 Benefits:
 
 Immediate bug detection
 No integration 
 
 
 
 JaCoCo Pluging-- generate report
 
Installation--

Login as a root user
sudo su -

Install Jenkins

cd /opt/

wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo

sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key

yum install jenkins -y --nobest

Enable and start the jenkins service

systemctl enable jenkins

systemctl start jenkins


admin
admin



--
PAT-

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

freestyle project

Build:

invoke top level maven projects

mvn clean package

Jenkins Home Directory  -- /var/lib/jenkins/


------

Global Tool Configuration

--

Sonar deatils in POM.xml
nexus credentails  in /conf/settings.xml
nexus repo in POM.xml

Nexus Credentials
-----------------
in  maven HD conf/settings.xml 

<servers>
..
...
.
.
 <server>
      <id>nexus</id>
      <username>admin</username>
      <password>admin</password>
    </server>
	


  </servers>
  

repositories>
			<repository>
			      <id>nexus</id>
			      <name>Group Repo</name>
			      <url>	http://3.110.165.154:8081/repository/mss-group-repo/</url>
			</repository>  
	</repositories>
	
	aslo
	
	change in settings.xml
	
	   <mirrors>
    <mirror>
      <id>nexus</id>
      <mirrorOf>*</mirrorOf>
      <name>Group repo</name>
      <url>	http://3.110.165.154:8081/repository/mss-group-repo/</url>
    </mirror>
  </mirrors>
  
  
  /var/lib/jenkins/workspace/wallmart-dev/target
  
  Building war: /var/lib/jenkins/workspace/wallmart-dev/target/maven-web-application.war
  
  --------
  
  to deploy in tomcat need to use pluging called deploy to container 
  
  Pluging Manager
  
  
Post-build Actions


give credentails of user whoch we added in tomcat-users.xml


Build Triggers


POLL SCM
      when there is an commit in the  git then only it will trigger job on scheduled  time 
	  jenkins 
Build Periodically
      Trigger a job at scheduled time irrespective of change in the code.
github Webhook
      github only push the changes to jenkins to trigger the job
	  
Settings;

   WebHook
http://13.234.66.155:8080/github-webhook/

Discard old builds:

Abort the build if it's stuck:

Add timestamps to the Console Output

JACOCO  Pluging
    stop the deployment if not met the condition like 80% of code  coverage
  
  
IN Configure Jenkins 
  
 will configure mail 
  
  smtp.gmail.com
  23:25:33 Email was triggered for: Always
23:25:33 Sending email for trigger: Always
23:25:33 Sending email to: harishkumarbr38@gmail.com harishkumarbr8@gmail.com
23:26:33 Finished: SUCCESS

------
Jenkins Home Directory

/var/lib/jenkins/

jobs/
  job info
  
  wallmart-dev/
        builds/  nextBuildNumber  config.xml 
		   12/
		   13/
		     log   
			 
			 
workspace/
    contains source code 
   	wallmart-dev/               wallmart-dev@tmp/
	src/  target/  pom.xml
	
	
tools/

  contains the software which installed on Global tool configuration

users/
  user info..
  
  users.xml

plugins/
   pluging info
   
   
 freestyle Project  vs Maven Project Type
 by default                    manul instal plugging- maven Project type ---- need to install  Pluging call 
                                                        Maven Intrgreation Pluging
 .any language               . java language
 .install maven in            . maven can install in  only Global tool configuration
   server or tool configuration 
   
   
 plugin Management:

Deploy  to Container  - tomcat
 Deploy to weblogic - Weblogic - oracle
 Websphere Deployer   -Websphere ()IBM
 

 
 Restart of Jenkins:
  3 ways:
  
  1)
   systemctl restart jenkins
   
   2)
     Through urls
	http://13.234.66.155:8080/safeRestart	 
  
   http://13.234.66.155:8080/restart  
   
   
  3) 
    Through Pluggin called SafeRestart 
  
    Restart Safely  option in UI
	
	It wil call --
	http://13.234.66.155:8080/safeRestart


Are you sure you want to restart Jenkins? Jenkins will restart once all running jobs are finished. 


  
 http://13.234.66.155:8080/restart          # force restart
 
     Are you sure you want to restart Jenkins? 

 
---
Next Build Number Pluggin
 
to change to nextbuild number 

1) through server 
 
vi /var/lib/jenkins/jobs/wallmart-dev/nextBuildNumber 

2) Pluggin call Next Build Number
 we suppose to give greater than the current build number 
     # can see this plugin in job level
	  
---
JaCoCo 
----
SSH Agent
#docker
----
Email Extension # Suggestion plugging

--

SonarQube Scanner
 # directly configure SonarQube deatils in Jenkins only without configure in POM.xml.
 
 ---
 Audit Trail:
 
 # can see this Plugin in configure Jenkins page
 
 Audit 
  
   https://plugins.jenkins.io/
	
	---
Job Configuration History:
	
maintain congutaion of the job 	 and restore the job 
	  # can see this plugin in job level and system level 
	
---
Schedule Build
 
RUn a job at scheduled time only one time .
---

Build name and Description Setter:

we can do Customer Build number and name setter while creating a job- build Env
			 -------
Blue Ocean

---

EXternal Plugin

UCDeploy

----			 

Jenkins_Port =8080


RHEL

/etc/sysconfig
jenkins  --file

Ubuntu
/etc/default 
jenkins  --file

------------

Jenkins logs  available  on -/var/log/jenkins
jenkins.log
---
Views:


create view for usage


Jenkins Security:

 manage jenkins -- for admin
 
 Creating users:
 ------

Security:
 Manage users:
    Create  User:
	
   # wecan see this users in /var/lib/jenkins/users/users.xml
   
    #by default if we create users in jenkins they will have  admin access .
	
	to remove  admin access and  give proper access  got to 	
   Dashboard
Configure Global Security

LDAP- leightweight Directory Access Protocol


In authentication process, the identity of users are checked for providing the access to the system. 
While in authorization process, person’s or user’s authorities are checked for accessing the resources.
 Authentication is done before the authorization process, 
 whereas authorization process is done after the authentication process.


	In authentication process, users or persons are verified.	
	    While in authorization process, users or persons are validated.
		
		---
		Configure Global Security
Role-based Authorization Strategy  Plugin for Authorization
------
Authorization:
 Matrix-based security
 Project-based Matrix Authorization Strategy
 Role-Based Strategy
		
	-----------
 Project-based Matrix Authorization Strategy
::Enable project-based security
 add individual users including  admin ad provide access accordingly.
 
 
 ---------
 Build with Parameters:
 
 
 */${BranchName}
 $RevsionNumber
		
echo "................"
echo "selected branch name is : "$BranchName
echo "................"
echo "selected branch name is : $BranchName"
echo "................"
echo "Entered Revsion  is : $RevsionNumber"
echo "................"
echo "Entered Revsion  is "$RevsionNumber	


-------
Pipeline project type:

  vs FreeStyle vs  maven Project Type
  
 Intrgreation is easy
 scripts ,code
 
 
 Always  whenb we run job in jenkins it will point to below path
 
 /var/lib/jenkins/workspace/JobName
 
 /var/lib/jenkins/workspace/SQE
                                     target/*.war


 a) Scripted Way:
 
 node respresent in which server it will run 
 by default  master 
 node()
 or
 node('master')
 
 --
 /var/lib/jenkins/tools/hudson.tasks.Maven_MavenInstallation/maven3.8.3

${mavenHome}

maven-3.8.2
maven3.8.3

rsync

ssh agent plugin to connect the server with credentails , with user name and pemfile or paswd .
scp command: copy war file to to another  server  

ec2user is copying the file to webapps/ directory but ec2-user has ro access to write to webapps directory	
chmod -R 777 webapps/
 --
 node()
{ 
    def mavenHome = tool name: "maven-3.8.2"
    
    stage('Clone the Code'){
     
        sh 'echo "---cloning the code from Github---"'
        
        git branch: '${BranchName}', credentialsId: '45ea0ad7-34b3-4ae2-8be8-0b1432262ead',
        url: 'https://github.com/harishgowdabr/maven-web-application.git'

    }
        
        stage('Build the code'){
		// mvn clean package -Dmaven.test.skip=true
		//mvn -Dmaven.test.failure.ignore=true clean package
        sh "${mavenHome}/bin/mvn clean package -Dmaven.test.skip=true"
        
    }//Build
	
	 stage('Execute Sonar Report'){
        
        sh "${mavenHome}/bin/mvn sonar:sonar"
        
    }//Sonar
    stage('Depoy to remote Repo'){
         sh "${mavenHome}/bin/mvn deploy"
    }// to nexus
	
	stage('Depoying to Tomcat'){
        sshagent(['74499b02-e88e-440d-aaaa-0dd9c916e074']) {

      sh "scp -o strictHostKeyChecking=no target/maven*.war 
	  ec2-user@3.109.202.21:/opt/apache-tomcat-9.0.56/webapps/"
	  
}//ssh

        
    }//tomcat   scp: /opt/apache-tomcat-9.0.56/webapps//maven-web-application.war: Permission denied
	
	stage('mail'){
	}
	
}


####

Jenkinsfile  by default file we can have jenkins pipeline

//echo "GitHub BranhName ${env.BRANCH_NAME}"
  //echo "Jenkins Job Number ${env.BUILD_NUMBER}"
  echo "Jenkins Node Name ${env.NODE_NAME}"
  
  echo "Jenkins Home ${env.JENKINS_HOME}"
  echo "Jenkins URL ${env.JENKINS_URL}"
  echo "JOB Name ${env.JOB_NAME}"
  
----
 b)Declartive Way
 
 
 agent any means - any node to run this script
agent{
 label: 'dev'
}

---

pipeline{

agent any
/*
agent{
label 'NodeName'
}
*/


pipeline{

agent any
tools {
maven 'maven-3.8.2'
}

options()
{
timestamps() // it will add timestamps
buildDiscarder(logRotator(artifactDaysToKeepStr: '', artifactNumToKeepStr: '', daysToKeepStr: '6', numToKeepStr: '6'))
 // delete the old builds
}
triggers{
//Poll SCM
pollSCM('* * * * *')
//BuildPeriodically
cron('* * * * *')
//GitHub WebHook
githubPush()
}

    stages{
        stage('Cloning the code'){
            steps{
                 sh 'echo "---cloning the code from Github---"'
        
        git branch: '${BranchName}', credentialsId: '45ea0ad7-34b3-4ae2-8be8-0b1432262ead',
        url: 'https://github.com/harishgowdabr/maven-web-application.git'

            
            }//step
        }//stage

        stage('Building the war file'){
        steps{
        sh "mvn clean package -DMaven.test.skip=true"
        //mvn clean package -Dskip.Tests
        }
        }
        
        stage('sonar Report'){
        steps{
        sh "mvn  sonar:sonar"
     
        }
        }
        
        stage('INTO Remot Repo'){
        steps{
        sh "mvn clean deploy"
     
        }
        }
        stage  ('Depoying to Tomcat'){
       steps{
        sshagent(['74499b02-e88e-440d-aaaa-0dd9c916e074']) {

      sh "scp -o strictHostKeyChecking=no target/maven*.war 
	  ec2-user@3.109.202.21:/opt/apache-tomcat-9.0.56/webapps/"
     }//shh
     }//step
     }//stage
    }//stages
	
	post{
	
	success{
	
	}
	
	failure{
	  
	  }
	  abort{
	  
	  }
	  always{
	  
	  
	  }
	}
	
	
}//pipeline
------------------------


Example -2
----------
pipeline {
    agent any
stages {    
  stage('CreateDirsandFiles'){
  steps{
  sh "touch test.py"
  dir('/tmp/pipeline/'){
  sh "touch pipeline.txt"
  sh "touch test.sh"
  }
  }
  }

}
}

Example -3

pipeline {
    agent any
stages {    
  stage('run Java'){
  steps{

  sh "java -jar jarname"
  }
  }
  }

}
}

---

Build with parameter with declartive :

pipeline {
    agent any
    
    parameters {
    choice(name: 'BranchName', choices:['master','development','dev','qa'],
	description: 'Using this we can pass the branch names' )
	
	string defaultValue: 'NA', description: 'Please enter RevisionNumber', name: 'RevisionNumber', trim: true
	
	
    string(name: 'PersonName',  defaultValue: 'Bhaskar Reddy', 
	description: 'This Parameter, will use to pass the persona name')
    }
    stages {
        stage('CheckoutCode') {
            steps {
               git branch: '${BranchName}', credentialsId: '45ea0ad7-34b3-4ae2-8be8-0b1432262ead',
        url: 'https://github.com/harishgowdabr/maven-web-application.git'
             sh "echo The persona name is: ${params.PersonName}"
			 
			 sh "echo  RevsionNumber is : ${params.RevisionNumber}"
			  sh "echo  Branch is : ${params.BranchName}"
             }
        }
    }
}

--------------

pipeline {
    agent any

 
    parameters {
    choice(name: 'BranchName', choices:['master','development','dev','qa'],
	description: 'Using this we can pass the branch names' )
	
	string defaultValue: 'NA', description: 'Please enter RevisionNumber', name: 'RevisionNumber', trim: true
	
	
    string(name: 'PersonName',  defaultValue: 'Bhaskar Reddy', 
	description: 'This Parameter, will use to pass the persone name')
    }

    stages {
        stage('Hello') {
            steps {
                echo 'Hello World'
                
                
                git branch: '${BranchName}', credentialsId: '45ea0ad7-34b3-4ae2-8be8-0b1432262ead',
        url: 'https://github.com/harishgowdabr/maven-web-application.git'
             sh "echo The persona name is: ${params.PersonName}"
			 
			 sh "echo  RevsionNumber is : ${params.RevisionNumber}"
			  sh "echo  Branch is : ${params.BranchName}"
            }
        }
        
          stage('CreateDirsandFiles'){
  steps{
  sh "touch test.py"
  dir('/tmp/pipeline/'){
  sh "touch pipeline.txt"
  sh "touch test.sh"
  }
  }
  }
        
     
     
        
    }
}

--
Multi Branch pipeline Project Type

create 50 Branches at one shot .. if we have common file 

..

FileName - Jenkinsfile  -- 

Go to git repo-- search for Jenkinsfile-Declarative-Pratice -- 
file name in all the branches, for those branches it wil create a Job.

Scan Multibranch Pipeline Triggers--- feature act li poll scm chmages if found triigers build

Scan Multibranch Pipeline Now -- will trigger build manually.


Blue Ocean will use this MUlti branch pipeline concept


--------

Jenkins Backup:

Thin backup pluggings:
Backup:


  -- we can seee in manage Jenkins -Uncategorized
 
 Thin backup 
 
 
 settings
    path to store the backup:
	/var/lib/jenkins/
	                   mkdir /var/lib/jenkins/jenkinsbackup
					    it will create as Root user
						so change owner n group
						
						chown -R jenkins:jenkins backup
						
						
	/var/lib/jenkins/backup  in jenkins UI  in setting s ThinBackup

Max number of backup sets -- 100
  -1 number of backup 	
  
  
  
  Backup schedule for full backups *** 1hr
  
  * * * * *
Backup schedule for differential backups   # updated backup



Jenkins Migration:

Jenkins 2.289.3  version

1) acces too jenkins:
 Install jenkins in new server with same version as in old server .
 It will create /var/lib/jenkins/ directory in new server  rename it to jenkins_bak
  stop it 
 copy the configure file jenkins file from old server (/etc/sysconfig   , /etc/default) to new server 
 
 start it 
  
 2)  Job Import  Plugin  
 
 install in new server
    give credentails of jenkins url of old server
	
	---
	
	
	Master Slave Architecture:***
	
TCP /IP Protocal

Connection Type is SSH	
	
	
	job info is maintain in master only.
	
	
	Source code is maintain in Slave.
		
labelname is collection of nodes avilable node it wil run he job

use lables so that it wil act as Load balancing..
	
	------------
	
	Manage Nodes and Clouds
	
	instal java and  Git in Nodes /slaves 
	
	 
	create  path to have node directory in node server
	mkdir node1
	
	/home/ec2-user/node1


3.110.179.182 -- node1
	
	
	
	INFO: Both error and output logs will be printed to /home/ec2-user/node1/remoting
<===[JENKINS REMOTING CAPACITY]===>channel started
Remoting version: 4.7
This is a Unix agent
Evacuated stdout
Agent successfully connected and online


/home/ec2-user/node1/remoting

remoting.jar  # with this jar only nodes n master will communicate

to run the job in nodes -- go to job n configure in genaral -Restrict where this project can be run

label expression (select node name r label name)

	For Pipeline project type


 node(nodeName/LabelName)
{ 

--
 node('wallmart-node')
{ 


 node('nodes')
{ 
------

pipeline {
    agent{
	label : 'nodes'
	}
	
	-----
	
	pipeline {
    agent{
	label : 'wallmart-node'
	}
	----
	Number of Executors
	
	in node configure page
	
	------------
	
	
	Jenkins shared Libs:
	
	
	Reuse of pipeline scripts
	
	
	1:create scripts and store in git
	
	 steps 2  Add GitHub Shared Library Repository to JenkinsManage 
	 
	 Jenkins- Configure System -Global Pipeline Libraries

sharedLibs

    3 :  to use this  shared scripts
	
	
To access the shared libraries, in the Jenkinsfile (declarative pipeline)
	   in  pipeline  job only
	   
	@Library('sharedLibs') _
pipeline{

agent{
label : 'wallmart-node'
}
tools {
maven 'maven-3.8.2'
}
         agent {
		  label: 'nodes'
		 }
             stages{
                 stage('Gettimg code from Git'){
                     steps{
                         git branch: 'dev', credentialsId: '45ea0ad7-34b3-4ae2-8be8-0b1432262ead', url: 'https://github.com/harishgowdabr/maven-web-application.git'
                     }
                 }//
                 
                 stage('Building file'){
                     steps{
                         //sh "mvn clean package"
                         stages('Build')// from sharedLibs
                     }
                 }//
                 
                 stage('Sonar report')
                 {
                     steps{
                         //sh mvn sonar:sonar
                         stages('SonarQube Report')
                     }
                 }
             }
               }	
			   
-----------

Jenkins CLI:


jenkins-cli.jar  download 

ip:8080/cli 
/home/mobaxterm/Desktop/DevOps-Cloud/jenkinscli


java -jar jenkins-cli.jar -auth admin:admin -s http://13.234.66.155:8080/ -webSocket help

			   
	JENKINS_USERNAME=admin
	
			   11754699d36ef07df95344c0ad78dea078
			   
			 jenkinsUserName=`grep JENKINS_USERNAME jenkinsCredentails.properties.sh | cut -d "=" -f2`
jenkinsPasswordToken=`grep JENKINS_TOKEN jenkinsCredentails.properties.sh | awk -F = '{ print $2 }'`  
			   
java -jar jenkins-cli.jar -s $jenkinsUrl -auth $jenkinsUserName:$jenkinsPasswordToken -webSocket build 
		          $jobName -s -v -p BranchName=$branchName  -p RevisionNumber=$RevisionNumber   
				  
------------				  
	CI/CD for Node js Project

	nodeJS  Pluggin
	
	
	GLobal tool Configuration --
	  
	   NodeJS - NodeJs17.40
	   
	   
	   
	 
node{

stage('CheckOutCode')
{
git credentialsId: '45ea0ad7-34b3-4ae2-8be8-0b1432262ead', 
url: 'https://github.com/harishgowdabr/nodejs-app-mss.git'
}

stage('Build')
{
nodejs(nodeJSInstallationName:'NodeJs17.40'){
sh "npm install"
}
}

stage('ExecuteSonarQubeReport')
{
nodejs(nodeJSInstallationName:'NodeJs17.40'){
sh "npm run sonar"
}
}

/*stage('UploadArtifcatsIntoNexus')
{
nodejs(nodeJSInstallationName:'NodeJs17.40'){
sh "npm publish"
}
}
*/
stage('RuntheApp')
{
//sh "node app.js"
sh "npm start &"
}

}






Maven Java         Node Js
----------         -------
pom.xml            package.json

mvn sonar:sonar     npm run sonar (OR) node sonar-project.js

sonar details in          sonar details in sonar-project.js
 Pom.xml
 
mvn deploy         npm publish

nexus details      nexus details in
in POM.xml            .npmrc


to get nexus token for node js app
echo -n "username:password" | openssl base64

echo -n "admin:admin"  | openssl base64

------------------------------------------------


 node_modules
  
  
  
  
  ---sonar-project.js
   Sonar details
    <sonar.host.url>http://13.234.66.155:9000/</sonar.host.url>
		<sonar.login>7039883a8c91a3ca3ad24493e12ea32590421a12</sonar.login>
		
		
		-----------------
		
		
		Resume:
		
		HarishKumarBR_5Years_DevOps.doc
		
		
		----------------------
		Monitoring tools:
		
Application Monitoring tools
----------------------------

NewRelic
AppDynamics
DataDog
Nagios
Zabbix
Grafna and Prometheous --> K8s 

Cloudwatch --> Service --> AWS


Log Monitoring tools
--------------------

Splunk
Logentries

ELK  Stack --> Elastic Search, Logstash and Kibana




wallmart

wallmart.log

ERROR


NewRelic + PagerDuty


newrelic

harishkumarbr8@gmail.com

H@r!$h1234




Very useful video for Jenkins Admin user password reset.

https://youtu.be/TnbzCae--X0

Very useful video for Jenkins Pipeline Parallel Stage execution.

https://youtu.be/KOJXR8CHpKI

---------------------

AWS:

requires to hostour apps

servers
databases
Storage(disk)
Networking
Routers
Switches
Cables
Firewalls.....

	
Application
-->
Database
-->
OS
-->
Haraware	

Data Center    physical Machines

all dev , operation teams connected  to server to host, maintain ,manage apps 

challengers:

cost
maintainace
Scalability

power supply
coolling system

capital expenditure -capex

investment
physical security
data security

support engineers --

Maintainces effort


Scaling:

 On primise Infrastructure :
 
 
 takes time to delivery the required infrastructure
  
  Datacenter Infrastructure management
------------------------------------------------------
1.	Dedicated space
2.	High bandwidth
3.	Redundant power supply
4.	Support Availability
5.	Leadership Experience
6.	Time consuming
7.	Higher maintenance Effort
8.	Capacity Planning

Business requirement
-------------------------------
1.	High Availability
         Data and application should be accessable in anytime/ allways avilable
2.	Fault Tolerant
          Ability to withstand the failures
3.	Scalability:
          Increases r deceases the capacity of the infrastructure via statically
4.	Elasticity
         grow r Shrink the capacity of the infrastructure resources dynamically
Big Billion offers:

Cloud Service:

  Services on demand, pay as you go model
  Any Service made available to the users on demand via internetfrom a cloud computing providers servers

example : Zomato , swiggy  

Cloud Computing
------------------------
Delivery of comuting services like servers, storage, databases etc over internet hosted 
  remote data centers manages by Cloud Service Providers CSP		
		
	Advantage of cloud
---------------------------
1.	cost-Effectiveness - Pay as you Go
      eliminates CAPEX
2.	scalability and elasticity
        vertically and horizontal scalability
3.	Reliable and High Availability
4.	speed or Agility
      get infrastructure in fraction of minutes
5.	Deploy globally in minutes
          expand the business globally
6.	Security	


Types of cloud
---------------------
1.	public cloud - AWS, GCP and Microsoft Azure
        Owned and operated by    3 rd party CSP
2.	private cloud - Openshift and IBM Cloud
       used by single business organisation , physically located
	      
3.	Hybrid cloud
      combination public and private
        some r own data center and some are cloud.
4.	Multi cloud
     organization depends on multicloud  
	 appls on AWS, application on Azure
	 
	
Popular Cloud providers
---------------------------------
•	AWS
•	Microsoft Azure
•	GCP
•	VMware
•	IBM Cloud
•	Oracle Cloud
•	Rackspace
•	Redhat
•	Salesforce
	 
	Cloud Service Models:

•	On Premises - Networking, Storage, servers, Virtualization , O/s, Middleware, Runtime, Data , Applications(By own)
•	IAAS - Networking, Storage, servers, Virtualization
        EC2  (Os , java install , )
•	PAAS - Networking, Storage, servers, Virtualization , O/s, Middleware, Runtime
        EKS, Elastic beans stack
•	SAAS - Networking, Storage, servers, Virtualization , O/s, Middleware, Runtime, Data , Applications	
         github, sonar Cloud, office 365
		 
	
	
	Software --just use application
	 Platform - development of application and  use application n managing data
	Infrastructure - integration of infra n development of application and  use application
	
	
	-----
	
	Car  
	
	On premise ---Own  car
	
	IAAS -- Car leased
	
	PAAS - Car Hired
	
	SAAS - Taxi
	
	
	Amazon Web Service:
	
	
	Retail  , E-commence
	
	Sub organisation of Amazon.com 
	
AWS Global Infrastructure
------------------------------------
                         old-   Region -            25,    planning 8 more
                            Availability Zones - 81, planning 24 more	
	
	84 Availability Zones within 
	26 geographic regions around the world
	
	24 more Availability Zones and 8 more AWS Regions in Australia, Canada, 
	         India, Israel, New Zealand, Spain, Switzerland, and United Arab Emirates (UAE).
Regions:

Geographical Locations
 logical name 

AvailabilityZones -AZ:

Acutal Data Centre
Isolated Locations	
	Phyiscal
	

How to choose the right region?
-------------------------------------------
•2	pricing
•1	End User/Customer Location
•3	Latency (To check the latency https://www.cloudping.info/ or https://ping.psa.fun/ )
         access time of ur application
•4	Security and Compliance Requirement
•5	Service Availability
	
	
	1a -A.Z  --250KM ---	1b - A.Z--- 250Km - 1c A.Z
	
	Multi Region Applications
	
	
	Asia Pacific (Mumbai)
ap-south-1
	Europe (Frankfurt)
eu-central-1



EC2

Elastic Compute Cloud


Computer in Cloud
as many server u required
scale up , down to handle changes




Computer:

OS
CPU/Memory
HardDisk
Network Card
Firewalls

EC2 Instance components
-----------------------------------
•	AMI's  - Amazon Machine Images - pre configured package that contains OS and some application
•	Instance type
•	EBS(local storage)
•	IP Addressing
•	Security Groups
•	KEY pair


Once we  create account in AWS -we can create max 20 instances per EC2 region 

8 cpu and 32gb Memory   -- application
8 cpu and 16gb Memory   --- Jenkins, k8s, Docker Swarm
4 cpu and 8gb Memory  -- LB ,Apache/Weblogic

Instance type:

General Purpose
          Balanced Memory , CPU
		  
		  A, M, T Series
		  A2
		  M4 , M5 , M5a 
          t2 , t3, t4
Compute Optimized
         More CPU & RAM  , batch process ,High performance computing 
	    C series
	     C4, C5
Memory Optimized
        More RAM  , in memory DB  in-memory caches, and real time big data analytics
         R , X ,Z 
		 R5, R4, X1 z1d
   High memory Optimized Instances

      U  series
Accelerated Computing
        Graphical processing , Machine learning
		P , G , F Series
		P3, P2, P4, G5, G3, F1
         
Storage Optimized
        better read and write opertaion to disk, low latency sequential read and write access to 
		               very large data sets on local storage
	    I D H Series
		I3 D2 D3 H1

Instance Family & Type
---------------------------------
1.	General purpose – balanced memory and CPU (t2, m3, m4)
2.	Compute optimized – More CPU then RAM (c3, c4, cc2) – C types
3.	Memory optimized – More RAM – M type and R type
4.	Storage optimized – Low latency (d2, i2, i3) – D and I type
5.	Accelerated computing (GPU) – Graphics optimized
6.	High memory Optimized – High RAM, Nitro system
7.	Previous generation
8.	EBS Optimized (Option for higher IOPS performance)



EC2 Purchasing Option
----------------------------------


On Demand: -
------------------
•	Most expensive purchasing option
•	Most flexible purchasing option
•	You are charged only when instance is Running(billed by hour)
•	You can provision/terminate an instance anytime
•   Irregular Workloads,Pricing is per instance hour

Reserved: -
-----------------
  Scheduled Reserved Instances
•	Allows us to purchase an instance for a set time period (1/3 yrs
•	Significant price discount
•	Once you buy a reserved instance, we are responsible for the entire price  
       regardless of how often we use it

Spot: -
-----------
•	Amazon sells the unused instances, for short amount of time at lower price
•	We can Bid on an instance type & only use when the spot price is equal to or below your bid price
     Charged by hour
•	Spot price fluctuate based on supply & demand in market



Dedicated Instance
--------------------------
•	Instances running on hardware that’s dedicated to you. 
    If you stop/start instance, you can get some other hardware somewhere else.

Dedicated host
---------------------
•	Physical dedicated server for your use. It’s always the same physical machine for as long as you are paying.

Instance Family & Type
---------------------------------
1.	General purpose – balanced memory and CPU (t2, m3, m4)
2.	Compute optimized – More CPU then RAM (c3, c4, cc2) – C types
3.	Memory optimized – More RAM – M type and R type
4.	Storage optimized – Low latency (d2, i2, i3) – D and I type
5.	Accelerated computing (GPU) – Graphics optimized
6.	High memory Optimized – High RAM, Nitro system
7.	Previous generation
8.	EBS Optimized (Option for higher IOPS performance)

Instance Type Components
---------------------------------------
•	Family: Categorizing instance types based on what they are optimized for
•	Type: subcategory for each family type
•	vCPUs: number of virtual CPUs the instance type uses
•	Memory: Amount of RAM the instance type uses
•	Instance Storage(GB): local instance storage volume(hard drive)
•	EBS Optimized Available: Indicates if EBS optimization is an option for the instance type
•	Network Performance: Rating based on its data transfer rate(bandwidth)


How are we charaged for using EC2?

1>  Purchasing options
2> Instance family and type								
3> EBS Optimized
4> AMI Type
5> Data Transfer																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																									fer
6> Regions


 1>>>>>>AMI:
Amazon Machine Images
Pre configured package required to launch Ec2 Instances including os , software packages and other settings,
Virtual Servers in Cloud

Thing you do to select an AMI
-------------------------------------------
AMIs come in 2 main categories: -
1) Community AMIs:
- Free to use
- Generally it contains only the OS, basic free software

2) AWS Marketplace AMIs:
- pay to use
contains OS and 
- Generally comes packaged with additional licensed software

3) My AMIs:
- AMIs that you can create yourself
---------------------------------------------

2>>>>>>>> Instance Types 

vCPUs , memory , EBS.


EC2 -- CPU and memory

Instance Storage --

a)Instance store - Local Storage  , temporory storage- storage from EC2 box -- 
                     loss of storage/date  when it is stop/terminate
                    underlyimg drive fails -- DAS
 
b)EBS  --SAN - Storage Area Network  , storage from  another box  ec2 or 	
 consitence disk attached to the box where it is running  -- Root Volume- NAS
 
 
 
3>>>>>Configure Instance details:

 Number of Instances ,
 Network :  
          VPC  - custom VPC
		  Subnet
     ap -south -1
     Asia pacific 
  Auto assign pulblic IP:
  
  Protect against Termination
  
  Userdata:
    Boot Strap Script  , we can execute some commands , while creating server.
	
4>>>>>>>>> Add Storage:

 EBS -Disk,
 Volume
Root volume -- booting OS , instal software  /dev/sda1

additional volume --  db , jib ,jenkins job- mount to addtional storage 


EBS volume type:

IOPS - Input output operations per sec per GB

Speed 

i)Solid State Drive Backed Volumes - SSD
. General Purpose SSD
     gp2 # default
	 gp3
. Provisioned IOPS SSD
    io1
	io2

ii) Hard Disk Drive Backed Volume - HDD
. Throughput Optimized HDD -st1
. cold HDD - sc1

iii) Magnetic Standard

5>>>>>>>>>>> add tags

meta data-- key value

6>>>> Security Groups

Security Groups-SG
-------------------------
1. Act as a firewall for any EC2 Instance
2. Control the traffic by Inbound and Outbound rules
3. SG is stateful means if u allow rule in inbound it automactically allwoed in outbound 
Network security 
Inbound rules and Outbound rules

5 SG per EC2  instance
can only have permit Rules, cant have deny rules
Operates in Instance level 
statefull - return traffic is automactically allowed

--
NACL 
Firewall at Subnet level
Stateless
It permit allow as well deny
Number listof Rules -- 32766

 1 subnect - NACL
 1 NACL = multi Subnet
 
 Once we craete VPC by default , NACL will create n associated to  all subnets in VPC

7>>>>>Key Pair
ssh key 
public key (inside server wil  have in ~/.ssh/authorized_keys) and
Private  key  (Pem file which we have)

public access aenied
timeout issue

CloudPing.info
https://www.cloudping.info

AWS latency test
https://ping.psa.fun


IP Address
-----------
1. Public IP - Accessible from Internet and will change after restart.
2. Private IP - Not able to access through Internet. It should be from any class, A, B, C 
                Access Ec2 within the network -VPN
3. Elastic IP - Fixed Public ip and will be chargable if we not used it.
            If we associcate it to EC2 instance nas that instance is running it will not charge.

ping IP

telnet Ip port

curl -v telnet://Ip:22

We can have only private IP 

2/2

system check- under lying h|w
instance state check

/dev/sda1  -- root volume

lsblk  	- list  block storage
df -kh 

Meta data once u login :

curl http://--ip--/latest/meta-data
GET http://--ip--/latest/meta-data

Storage - services:
S3
EFS
Glacier
SnowBall
EBS



default - Delete on Termination


user -data verication -- sudo cat /var/log/cloud-init.log


Ec2 - cpu and memory


Storage services
--------
1. Local storage - temperory - Instance store
2. EBS Storage
3. EFS storage
4. S3


Storage types
---------------
1. Block storage - Data store in multiple Block and each block have their inode value - 
              Ex EBS - SSD(GP2/GP3/IO2/IO3) or Magnetic type - root volume - Good performnace for I/O
2. File storage - Data store in a file - Ex EFS
3. Object storage - Data store as an object. Each object have their end point - Ex S3




.Block storage:
	Data equally divided into block ,each block has address called index
	not conatin  metadata in block , performace is good - writing and reading 
    Ex: EBS	
.File Storage -System:
	Traditional file system , path , metadata
	
	To read and write the data we need mount the block and file storage to server 
    Ex: EFS , NFS
.Object Store:
	No need to mount this storage to server to access the data from anywhere 
	Each and every object which we are uploading to object storage whil have unique object id and object url
	using this end point we can anywhere
    ex: dropbox , s3, drive 	


EBS:

1 EBS storage can  be attached  1 ec2 Instance at given point time.
   we can dettach and attach to any other ec2 instance.
   and ec2 instance and EBS volume are should  be in same Az with region 
   
 EBS cant be mounted /shared with  multiple ec2 Instance at a time but 
 we can have 2 EBS storage  attached to 1 ec2 instance.



max size of EBS volume
1600GB /16TB

min size of EBS volume
1GB

Note:-
------
1. We can access or read/write on EBS and EFS after mounting it.
2. EBS volume and EC2 will be in same AZ if you want to mount EBS to EC2.
3. The min size value of EBS volume is 1 GB and Max 16384 GB.

---------------
Note:-  
--------
1. We can not mount one EBS volume simultaneously to multiple EC2.
2. You can increase the size of the created volume on fly but not able to decrease.

Usecase

Attach EBS storage to  Jenkins Server:

lsblk

df -kh 

Volume - created - attached to ec2 instance - format - mount to the path 

Elastic Block Store 

.Create Volume ->
  .. volumn type(SSD/IOPS) ->
      ...Size (1GB/1634GB) ->
	     ... AZ (same as Ec2 Instance) ->
			....Encryption (CMK)
			
			Created Volume
			
			
Volume -->Action --> Attach Volume -- Ec2 Instance 
			
			device name -- /dev/sdf -## additional volume
			
lsblk

#sudo file -s /dev/-xvda2 ## root volume already formated
sudo file -s /dev/xvdf ## addtional volume need to be formated  as it raw storage

# formats
sudo mkfs.ext4 /dev/xvdf

sudo mount /dev/xvdf  /var/lib/jenkins/  ## temperory mounting

-------------------

	[root@ip-172-31-94-136 opt]# lsblk
	NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
	xvda    202:0    0  10G  0 disk
	├─xvda1 202:1    0   1M  0 part
	└─xvda2 202:2    0  10G  0 part /

	only  one volume 

	ap-south-1b

	raw storage

	[ec2-user@ip-172-31-87-30 ~]$ sudo file -s /dev/xvdf
	/dev/xvda: DOS/MBR boot sector, extended partition table (last)

	[ec2-user@ip-172-31-87-30 ~]$ lsblk
	NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
	xvda    202:0    0  10G  0 disk
	├─xvda1 202:1    0   1M  0 part
	└─xvda2 202:2    0  10G  0 part /
	xvdf    202:80   0   5G  0 disk

	[ec2-user@ip-172-31-87-30 ~]$ sudo file -s /dev/xvdf
	/dev/xvdf: data

	attched now  2 volumes in AWS


	TO format: file system

	[ec2-user@ip-172-31-87-30 ~]$ sudo mkfs.ext4 /dev/xvdf

	after fomatted:

	sudo file -s /dev/xvdf
	/dev/xvdf: Linux rev 1.0 ext4 filesystem data, UUID=9c15add5-f815-4536-b657-91c7f7fc6691 (extents) (64bit) (large files) (huge files)
	[ec2-user@ip-172-31-87-30 ~]$

	to temporary mount:

	sudo mount /dev/xvdf /var/lib/jenkins/   ##after restart machine it will unmounted

	to permanent mount :

	take backup:
	sudo cp /etc/fstab /etc/fstab.orig

	sudo blkid 

	 ## take uui here 
	dev/xvda2: UUID="c9aa25ee-e65c-4818-9b2f-fa411d89f585" BLOCK_SIZE="512" TYPE="xfs" PARTUUID="b3824610-751c-49f8-a4a9-068fa13d9460"
	/dev/xvda1: PARTUUID="3e18b896-4879-4ede-8711-a58017aff81c"
	/dev/xvdf: UUID="9c15add5-f815-4536-b657-91c7f7fc6691" BLOCK_SIZE="4096" TYPE="ext4"


	##add uuid in etc/fstab 

	sudo vi  /etc/fstab

	UUID=b074e53e-e0f0-4dc8-876d-e6093f3d8404  /var/lib/jenkins/  ext4  defaults,nofail  0  2


  to validate entries are correct in fstab
  
  sudo unmount /var/lib/jenkins/
  sudo mount -a   # mounted back as there  an entry in fstab
  
  if any error revert sudo mv /etc/fstab.orig /etc/fstab 
  
	later need to change owner

	sudo chown jenkins:jenkins -R /var/lib/jenkins
	service jenkins restart

we can modify the EBS Volume while using it we can increase and change volume type aslo

	Volume Created and attched and formated and mounted
	
NO DISK SPACE LEFT ON THE DECIVE:


Lab: -
-------
Create an EC2 Instance and create Volume in same AZ and attach the volume to EC2.Create filesystem on 
the mounted Volume by mkfs.ext4 /dev/xvdf and then mount 
any directory to the mounted volume by mount /dev/xvdf /var/lib/jenkins.
----

	g4ad.2xlarge  - 16 32
	
	
EBS Snapshot
-------------
Snapshot is nothing backup of your EBS Volumes.

.Snapshot are usefull to recover /restore  the date  in case  of any failure in EBS volume.
.useful to migrate our data from one AZ to  another AZ  within region or we can move from 1 region to another region 

volume - snapshot -volume
5000 EBS volumes per account
upto 1000 snapshot per account
 Snapshot stores in s3 cant access it direclty , throgh APIs only
  EBS volume - Az specific
  Snapshot - region specific
  Incremental Snapshot
  
  take snapshot of non - root volume while running also
    take snapshot of  root volume need to stop it 


server migration to one Az to another Az , or 1 region to another  region means data migration

one Az to another Az  of volume::

create snapshot in 1 az of volume 
action -create volume in another AZ using this snapshot
         	attach volume to the server  in same AZ
			mount 

dev/sda1 --root

1 region to another  region of volume

create snapshot in 1 az /region of volume 
action -copy snapshot to another region 
        create volume  from snapshot
		attach volume to the server in same AZ
		mount (permanent/temperory)
		

We  cant attach snapshot direclty to the server
Volume created from snapshot not required ot formatting if  volume direclty created and  attached this need formated 
 like sudo  mkfs.ext4 /dev/xvdf
 


snapshots can be taken two types: -

1. Manually using AWS GUI, CLI, APIS etc

Volume snapshot or Instance snapshot

   check mark on the volume -> Actions -> Take a snapshot (no need to stop the server)

2. By creating Lifecycle manager (For periodically based on policy)
   Life cycle manager -> Specify settings -> On the basis of tags on that volume
   Target resource type -> volume
   Target resource tags -> Name and value
   Schedule details
   Retention Type   - 6 it wil maintain recent 6 snapshots
   
   
   
 
Restoring: -
-------------
In same region , different A-Z -> 
       -->  Create Snapshot 
		 
             Actions -> create volume

In different region - > use Actions -> copy -> Choose Region and then convert the Snapshot to volume in that region.

Lab1:- Take a snapshot of the Jenkins Volume and copy that snapshot to Singapore Region. create an Instance in Singapore Region and install Jenkins, and mount the snapshot after converting to volume to Jenkins EC2

Lab2: - Recovery of Key file

1) Stop Server Which you lost pem file
2) Create a server with new pem file in same AZ where you have server for which you lost pem file.
3) Detach root volume from the server for which u lost pem file and attach to new server as a additinal volume.
4) In New Server mount the volume and copy latest public key & un mount
 
 sudo mkdir -p /mnt/tempvol/

 sudo mount /dev/xvdf2 /mnt/tempvol/


 cat /home/ec2-user/.ssh/authorized_keys >> /mnt/tempvol/home/ec2-user/.ssh/authorized_keys

 umount /mnt/tempvol/
 
 
 
5) Detach volume from new server and attach back to existing server as a root volume(Root Device Type
/dev/sda1)


6) We can start the server and we can access using new pem file.

In Recovery Server
====================


Root Device Type
/dev/sda1

Additinal Volume Type

/dev/sdf
===================
  Where do EBS snapshots will be stored/maintained by AWS?--S3

EBS snapshots will be maintained in S3 buckets by AWS. But not available in our account.
  -----------
 ------------------
 Attach same volume/storage to 2 diff server
 
 shared volume/storage
 
 NFS - Network File System
 
 EFS -- AWS Service
 Its a manage NFS 
 managed Fle Stored for EC2
 Root volume will be EBS not EFS
 
 hared storage (EFS)
-------------------------------
We can mount this storage simultaneously.

EFS - Managed NFS -> you no need to configure NFS, managed by AWS. There is no fixed capacity,
 it can grow and shrink automatically.

Lab: - Create two EC2 in different AZ. Create EFS storage and share between two.

It can be shared to different AZ, Region or different Account.

Search EFS -> Create file system -> Name, VPC, Availability and Durability (Regional,(Multiple AZ) One zone -(1 AZ)) - create

It need NFS client or EBS client installed on the system to mount.

NFS Port -2049

Port open in SG which attach to EFS:

Install NFS client on both system
# yum install nfs-utils -y

Open the security group port 2049 of shared volume. You can get the Security Group id from netwrk section of EFS volume.
and add network range of VPC Cidr 


2 diffrent server same storage/sharesd volume
Mount the volume by below command

sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport 
fs-01088cdc7ba63835e.efs.ap-south-1.amazonaws.com:/ <opt/one/two>
--

sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport 
fs-01088cdc7ba63835e.efs.ap-south-1.amazonaws.com:/ <anotherPath>
							  
							  
							  
Amazon FSX client - For windows 
FSx - For windows
 
 S3: -
--------
 simple storage Service
Object Storage

Without mounting we can read and write on Object Storage from anywhere.
S3 use cases:

S3 is perfect place to maintain application static files like images, docs, audios, video file
S3 is perfect place to maintain application logs and backups.

state file in terraform will maintain in S3.

Data/object in S3 which we maintain wil have unique Id and Endpoint we can accces  the  oobject (file ) usimng HTTP and rest API

S3 Bucket 

Using AWS GUI ,CLI, API, SDK
S3 global service but its a region specific.
No OS in S3
S3 Bucket name is unique accoss all regions and accounts

from GUI max size upload is 160GB in S3.

How many s3 buckets we can create in one AWS account by default?
100 (Soft Limit). Can be extended this limit by working with AWS team.

What is the max limit in s3 ?
5TB/5000GB-- single file not s3 bukcet size


Can we do s3 replication without versioning enabled?
No


Security in S3:
Bucket level
Object Level

Public Access --> It's access for the objects in s3
				by default Block Public access
				
				
				
Bucket policies-
				json format

ACL --> Access Controll Lists is can be used to grant/share buket with other AWS Accounts. 

What is ARN in AWS?

Amazon Resource Name --> It's unique way of identified each resource(service- AWS , ELB, VPC, S3) in AWS.

arn:aws:<service>:<region>:<a.z>:<Id/NameOftheAWSResource>

arn:aws:s3:::<nameofbucket>

Prinipal (Who is  to access)- * means public, anyone 

 Action -  what he will do
 Resource ---AWS , ELB, VPC, S3

arn:aws:s3:::julymithuntech1234/*
here * means all the files in that bucket

In Bucket Policy:


{
  "Id":"PolicyId2",
  "Version":"2012-10-17",
  "Statement":[
    {
      "Sid":"AllowIPmix",
      "Effect":"Allow",
      "Principal":"*",
      "Action":"s3:*",
      "Resource": [
        "arn:aws:s3:::julymithuntech1234/*"
      ],
      "Condition": {
        "IpAddress": {
          "aws:SourceIp": [
            "54.240.143.0/24"
          ]
        }
      }
    }
  ]
}


versioning in S3:
Keep object versions as its changes once we enable it .
  to protect against accidental object/data deletionn or overwrites
  Once we enable versioning we cant be disabled 
bucket level versioning

StorageClass and Obejct life cycle

 charge in S3 :
 Size of the  obejct -file and storageClass in which we are maintain object.
 
 Object action  -->edit storageClass
 
 StorageClass:
 
.Amazon Standard               Default  -costly faster , durability ,performace, 3 copies in different AZ
.Amazon  S3 Standard Infrequent Access IA  -- 
.RRS - Reduced  Redundancy Storage //
.Amazon  S3 One -zone IA	
.Amazon  S3 Glacier
.Amazon  S3 Glacier Deep Archieve 
.Amazon  S3 Intelligent Tiering


Storage Classes
----------------------
By default each object which is upload to S3 maintained in standard Storage class.
S3 charges is based on the object size and storage class.

1. Standard class ->
    The files/data  which we are going to access frequently. 3 AZ
2. IA (Infrequent Access) ->
    The data is not going to access frequently for cost saving and less performance.3 AZ
3. RRS/One zone (Reduced Redundancy Storage) -> 
  Non critical $ Reproducible data. We can store in RSS.1 AZ
 Chances to loss of data.
4. Glacier->
  Archival data we can store in glacier with very less price. When we retrieve the data from 3 AZ
   Glacier it will be chargeable high. It take up to 4 hrs to read the data from Glacier. It is like a historical data.


Object Life Cycle -

 By creating Object Life Cycle rules we can transit objects from one storage class to another storage class and aslo
 set an expiration(delete) object


our S3 bucket  -Mangament - lifecycle rule 
 
 
Object Transition & Expiration can be automate using Object Life Cycle Rules.
--------------------------------------------------------------------------------------------------------

Object Lifecycle -> we can transit & move objects from one SC to another SC and also we can set 
expiration (delete) for the object using Object Life Cycle Rules.

Management -> Lifecycle Rules -> create Lifecycle rules
1. Name
2. Choose a rule scope
3. prefix
4. tags
5. Lifecycle rule actions

We can move from one class to another from any specific days or we can delete after some specific days.

To save the cost we implement Life cycle management.

Replication Rules:
Replication in S3 (Duplicate Copy) 
Replication of obejct.

already  uploaded files  in  the bucket   before  the replication rule files  wil not replicate  .
files will replicate    only after creating the replication rule.


Enable of  versioning is must for Replication in S3 in both soruce and destination bucket
----------------------------------------------
management -> replication rules -> create replication rules ->
   Name, status, source Bucket and scope, Destination and Bucket Name , IAM Role , storage class of replication

Replication can  be done in same region as well as in different region.
Same account same region
Different Region Same account
Same Region Different Account
Different Region Different Account

Max file size which we can upload in S3?
5 TB

How many buckets we can create in one account by default?
100 (Soft limit)


Snow Ball (Device)
--------------------------
Data transfer of huge data from in-premises to AWS.

Write a request to AWS or job, they will send device to your data center, you connect that device and 
copy all data and then the device will be move to AWS data center and then they connect and copy your data.


check metadata 
curl http://..../latest/meta-data
curl ifconfig.me 


=================
compute - EC2
storage -  EBS
           EFS
		   S3
		   SnowBall
Networking - VPC

VPC:

Virtual Private Cloud:

Secure servers , Isolated the servers

------


VPC: - Virtual Private Cloud (Private network)
Network -> Groups of devices which connected with each other some or the other way using network cables, 
routers, switches... etc.

LAN -> Local Area Network (Intranet)
WAN -> Wide Area Network (Internet)
		   
		   
Subnets - Sub networks
IGW- internet gateway
Routetable
NAT  - Network Address Translater
     NAT gateway /NAT Instance
NACL - Network Access Control List



In Default VPC all the  subnets are Public Subnets.

Subnets- 
	Public Subnets - Subnets have acccess to Internet.
		               if the  subnets has a route to IGW  in routetable (mention as 0.0.0/0 to IGW)
					   Subnets which are associated with IGW 
					   Servers in these subnets will have  accces to Internet
	Private Subnets - These subnets doesnt have access to Internet.
			           Subnets which doesnt have route to IGW in route Table
					   If the subnets which has route not linked to IGW in RouteTable
					   Servers in these subnets will doesnt have accces to Internet
					   
					   
	
	
1 VPC - Upto 200 Subnets	

1 region - 5 VPCs can create(Softlimit)					


****VPC Tool Box***********
-------------------
**1. VPC (max 5 VPC in one Account)
**2. Subnets (max 200 subnets in One VPC)
3. NACL (Network Access Control List)
**4. Routing Table 
        how to traffic should be routed from/to each subnets
		set of  rules
		
		1 route table  - as many Subnets
		1 subnets have 1 route table a time 
**5. Internet Gateway
        Virtual router   it will enable the internet to our network/ vpc
		logical device enabling traffic to be routed to/from the public internet
		Without IGW resource can talk to each other but not io internet 
6. NAT Gateway


1 IGW is attached to 1 VPC at any time 

VPC - region
Subnets  - Az


ELB -> Loadbalancer as a Service
--------------------------------------------

RDS -> Relational Data Base as a Service
------------------------------------------------------


CIDR - classless Inter-Domain Routing 
  method for alloactimg IP address and IP Routing
  CIDR range 0-32
  
  172.31.0.0/16
  
  /16  - siderblock /subnet mask
  
  32-n
  2
  
  32-16
  2
          16
         2     ==65536  IPv4 32 bit Ips addresss



Sider block is should be between 16- 28

Never see server  of  public  ip below  range
		RFC1918 Subnets
		The RFC1918 address space includes the following networks:
******Below are will be in Private Ips ***

		10.0.0.0 – 10.255.255.255  
		172.16.0.0 – 172.31.255.255  
		192.168.0.0 – 192.168.255.255 	
		
	*******************************************	
Private Ips can be same  as in intranet 
no public ips in below ranges
IP addresss Classes:

Class A ---0.0.0.0 - 127.0.0.0 --  (1.0.0.0 to 126.0.0.0)  - N H H H 

Class B --- 128.0.0.0 - 191.255.0.0                         - N N H H 

Class C --- 192.0.0.0 - 223.255.255.0                       - N N N H 

Class D --- 

Class E-


Priavte ips can same 


Network Bit  Host bit
----------------
Subnet CIDR should be Subset of VPC Cidr



https://www.davidc.net/sites/default/subnets/subnets.html




VPC Types: -

1)	Default VPC
2)	Custom VPC

Default VPC: -
•	Created in each AWS Region when an AWS account is created.
•	Has default CIDR, Security Group, NACL and Route table settings.
•	Has an Internet Gateway by default.

Custom VPC: -
•	Is a VPC on AWS Account owner creates.
•	AWS user creating the custom VPC can decide the CIDR
•	Has its own default security group, Network ACL and Route Tables.
•	Does not have an Internet Gateway by default, one needs to be created if needed.

Steps to create a VPC: -
1)	VPC
2)	Subnet
3)	Internet Gateway
4)	Route Table configuration

Public Subnet: - If a subnet traffic is routed to an Internet Gateway, the subnet is known as a public Subnet. 
If you want your instance in a public subnet to communicate with the internet over IPV4, 
it must have a public IPV4 address or an Elastic IP Address.

Private Subnet: - If a subnet does not have a route to the internet Gateway, the subnet is known as a Private Subnet. 
When you create a VPC, you must specify an IPV4 CIDR Block for the VPC.
 The allowed block size is between /16 to /28 netmask. The first four and last IP address of Subnet cannot assigned.

For ex: - for Network 10.0.0.0/16

10.0.0.0		Network Address     
10.0.0.1		Reserved by AWS for the VPC Router
10.0.0.2		Reserved by AWS for IP address of DNS server
10.0.0.3		Reserved for Future Use
10.0.0.255		Broadcast Address


32-n
2 
curl -v telnet://65.0.125.11:22


Note: - AWS do not support Broadcast in a VPC but reserve this Address.

Implied or logical Router and Router table: -

	It is the central Routing function
	It connects the different AZ together and connects the VPC to the Internet gateway.
	You can have upto 200 Route tables per VPC.
	You can have upto 50 Routes entries per route table.
	Each subnet must be associated with only one route table at any given time.
	If you do not specify a subnet to route table association, the subnet will be associates with the VPC route table.
	You can also edit the main route table if you need, but you cannot delete main route table.
	However you can make a custom route table manually become the main Route table then you can delete the former main as it is no longer a main route table
	**  You can associate multiple subnets with the same Route table.

Internet Gateway: -

	The Internet Gateway is a virtual router that connects a VPC to the internet.
  **	Default VPC is already attached with an Internet gateway.
	If you create a new VPC then you must attach the Internet Gateway in order to access the Internet.
	Ensure that your public subnet route table points to the internet gateway.
	It performs NAT between your private and public IPV4 address.
	It supports both IPV4 and IPV6.


A Virtual Private Cloud is a Virtual Network that closely resembles a traditional Networking 
that you operate in your own data center, with the benefits of using the scalable infrastructure of AWS.

OR

VPC is a virtual network or datacenter inside AWS for one client.

•	It is logically isolated from other virtual N/W in the AWS cloud.
•	Max 5 VPC can be created in one account and 200 subnets in one VPC.
•	We can allocate max 5 Elastic IP.
•	Once we created VPC- DHCP, NACL and security group will be automatically created.
•	A VPC is confined to an AWS region and does not extend between regions.


VPC will create in a Region

•	Subnet will create in AZ and in two AZ subnet will not same
•	Two VPC may have same CIDR because they are isolate from each other.
•	Once the VPC is created, you cannot change its CIDR block Range.
•	If you need a different CIDR size, create a new VPC.
•	The different subnets within  VPC cannot overlap.
•	You can however expond your VPC CIDR by adding new/Extra IP address Ranges (Except Gov-cloud and AWS-China)

Components of VPC: -

•	CIDR and Ip Address, Subnets
	Implied Router and Routing table 
	Internet Gateway
	Security Group
•	Network ACL
•	Virtual Private gateway
•	Peering connection
•	Elastic IP


.Create VPC-
10.0.0.0/24

Action -->  Edit DNS names
        -->     Edit resolution
		
		
		
.Create Subnets:
10.0.0.0/24

  1subnet:
		1a AZ
		Public_1a_Subnet
		10.0.0.0/26
   2subnet:
		1a AZ
		Private_1a_Subnet
		10.0.0.64/26
   3subnet:
		1b AZ
		Public_1b_Subnet
	    10.0.0.192/26
   4subnet:
		1b AZ
		Private_1b_Subnet
         10.0.0.128/26

		Auto assign pulblic IP:

		====================
		10.0.0.0/24
		32-24			8
		2            = 2  = 256 IPS
		total IPS - 5* Number of subnets
		 256    - 5* 4
		 256-20
		 236 --Available Ips to use
		 
------------
https://www.google.com/search?q=ip+addresses+classes&oq=ip+addresses+class&aqs=chrome.1.69i57j0i512j0i10j0i512j0i10l4.3613j0j9&client=ms-android-oppo-rvo3&sourceid=chrome-mobile&ie=UTF-8#imgdii=CCiPqI6qjv6G1M&imgrc=m_ayDQiEyzXrSM



https://www.davidc.net/sites/default/subnets/subnets.html


-----------


	.Create Subnets:
10.0.0.0/24

  1subnet:
		1a AZ
		PublicSubnet-1a
		10.0.0.0/26
   2subnet:
		1a AZ
		PrivateSubnet-1a
		10.0.0.64/26
   3subnet:
		1b AZ
		PublicSubnet-1b
	    10.0.0.192/26
   4subnet:
		1b AZ
		PrivateSubnet-1b
         10.0.0.128/26

		Auto assign pulblic IP:	disabled means assign public ips to server is disabled
	
Auto assign pulblic IP:  in subnet level -  

		select public subnet - action -Edit subnet settings-Auto-assign IP settings--Enable auto-assign public IPv4 address
	
Once we create VPC Default route Table wil create	

route - local

1  IGW to  1 VPC

ISP -Internet Service provider  - is the  Responsilbe  for assign public Ips 
--
	VPC:
Subnet
IGW - create and attach to VPC
Route Table- local (default) -attched  to subnets (default)
	 
create Route Table- #Public - route  --edit -  add route -0.0.0.0/0 --target - IGW
                     Subnet Assoication  -- #explictly add subnet -- ## Public subnet


create Route Table- #Private - route  --edit -  add route -0.0.0.0/0 --target - NAT Gateway
                     Subnet Assoication  -- #explictly add subnet -- ## Private subnet


Public server means- - Route table - IGW - 0.0.0.0/0 --Public --Subnet Assoication

Private Server means - Route table - NAR - 0.0.0.0/0  -- Private -Subnet  assoication

curl  -v telnet://Ip:port

Jump server/Batison Server- Public	server


In Public server  (source) we  can access Private server (destination)if they are in SAme VPC - range intranet


http://docs.gcc.rug.nl/hyperchicken/ssh-agent-forwarding-mobaxterm/

ssh-agent-forwarding:


sudo ssh-add -k ~/Desktop/Privatekey/MumbaiKey.pem

ssh-add -L

ssh -A ec2user@jumpserver

shh ec2-user@privateip

not worked agent-forwarding

so  copied pem in jump server/Bastion Server/Public server 

n ssh

  21/10/2021   23:18.36   /home/mobaxterm/Desktop/Privatekey  ssh -i "MumbaiKey.pem" ec2-user@65.0.125.11 
Last login: Thu Oct 21 17:41:46 2021 from 157.45.200.68
[ec2-user@ip-10-0-0-167 ~]$ sudo vi 1.pem
[ec2-user@ip-10-0-0-167 ~]$ sudo chmod 400 1.pem
[ec2-user@ip-10-0-0-167 ~]$ ls
1.pem

[ec2-user@ip-10-0-0-167 ~]$ ssh -i "1.pem" ec2-user@10.0.0.87     #Private server
[ec2-user@ip-10-0-0-87 ~]$ ls
[ec2-user@ip-10-0-0-87 ~]$


------------

Private server to connect  Internet  to install something
1..  conenct  to jump sever download required file 
		scp to private server
		
2..Enable internet access to Private server using NAT instance/gateway

		create a NAT Gateways  in public subnet- in samw VPC
		Elastic Ip

    .. server can access to internet .
			 not internet to access this private server 
			 
			 
NAT - Network Address Translater
is one network	device which enable access to internet fro private subnets.

private server to access API services (AWS resoruces)	

	

NACL	:

Network Access Control List:

Firewall

;


Each ENV there will be a separate network means

Dev - VPC , subnets 
Prod - VPC , subnets
Management - VPC , subnets  --jenkins , sonarQube , nexus

---

VPC Peering:

Servers in 1 vpc to talk to servers in another VPC in a private channel.

IF CIDR of VPCs are overlapping we cant do VPC peering

10.0.0.0/16 , 10.0.0.0/24 -- overlapping  - doesnt know where to route the  traffic, causes ambigute

10.0.0.0/16 , 10.1.0.0/24 --not overlapping 

we can do VPC peering 

Account
My account
Another account

Region
This Region (ap-south-1)
Another Region


Requestor;
same region
same account
different region 
different account


Acceptor;


same region
same account
different region 
different account


Peerring connection - Requestor -----Acceptor ----(Once Accept)  
add routes in both the sides  -- connected Privately 

In routes table: in private routes
10.0.0.0/24 -- Peering Connection
173.31.0.0/16   -- Peering Connection

to test ping  -- ICMP Protocal


VPC- 5 in one region

Subnet in 1 VPC -200





Day8: - 

Lab: -
NAT
NACL Farewall  at subnet level
vpc peering

Day9: -

ELB: -

Min 2 public subnet in diff AZ for implementing ELB

Types: -
1.	Application Load Balancer (Layer 7 Load balancer)- support HTTP & HTTPS
2.	Network Load Balancer (Layer 4 Load Balancer)
3.	Classic Load Balancer
Network Load balancer: -

Network Load Balancer cannot intercept the request. It simply forward the request and it’s not matter what url clients have hit.  

From Network load balancer only one application target group created because it does not intercept the request.

The request goes to ELB and the listener will forward the request to the target group. Routes based on IP Protocol.

Listener will not able to intercept for different two application.

For this we have to create different-different NLB for different-different Application.

Application LB:-

We can route host based from single ALB. We can route to multiple target Group as per the requested multiple application url.

Layer1: - Physical Layer
Layer2: - Datalink Layer
Layer3: - Network Layer
Layer4: - Transport Layer
Layer5: - Session Layer
Layer6: - Presentation Layer
Layer7: - Application Layer


Lab: -

Step 1: - Create two EC2 with User data in two different Private Subnet. This will download through NAT from public network. Open port 8080 also for Network CIDR. If you are create in one subnet then create in different AZ.
 

Step2: - Create war of maven-web-application and copy to jump server and then scp to both EC2 in private subnet under tomcat webapps.

Step3: - Configure Target Group , Load Balancer and listener for different-different application

 
 
Load-balancer: -

Load balancer -> create load balancer -> Network load balancer type -> name -> Scheme - Internet facing -> choose VPC - Mapping AZ and subnet (Min two) -> Listener (protocol, port and default action to target group) -Create a target group in another session protocol tcp port 8080 -> Health check settings -> create and add the servers check mark on include as pending

Loadbalancer - add target group -> create load balancer

Check all parameters of Load balancer and Target group

Access the loadbalancer url. Please allow your ip in SG of EC2 instances.






-------------------------------


#!/bin/bash
sudo su -

cd /opt
yum install wget unzip -y

##download java
wget -c --header "Cookie: oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm
yum install jdk-8u131-linux-x64.rpm -y

java -version


wget https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.54/bin/apache-tomcat-9.0.54.zip

unzip apache-tomcat-9.0.54.zip
cd /opt/apache-tomcat-9.0.54/bin
chmod u+x *.sh
ln -s /opt/apache-tomcat-9.0.54/bin/startup.sh /usr/bin/startTomcat
ln -s /opt/apache-tomcat-9.0.54/bin/shutdown.sh /usr/bin/stopTomcat
startTomcat





http://3.84.66.154:8080/  --jenkins viriginia 


[INFO] Packaging webapp
[INFO] Assembling webapp [maven-web-application] in [/var/lib/jenkins/workspace/sample/target/maven-web-application]
[INFO] Processing war project
[INFO] Copying webapp resources [/var/lib/jenkins/workspace/sample/src/main/webapp]
[INFO] Webapp assembled in [165 msecs]
[INFO] Building war: /var/lib/jenkins/workspace/sample/target/maven-web-application.war
[INFO] WEB-INF/web.xml already added, skipping


[INFO] Installing /var/lib/jenkins/workspace/sample/target/maven-web-application.war to 
/var/lib/jenkins/.m2/repository/com/mt/maven-web-application/0.0.4-SNAPSHOT/maven-web-application-0.0.4-SNAPSHOT.war

[INFO] Installing /var/lib/jenkins/workspace/sample/pom.xml to 
/var/lib/jenkins/.m2/repository/com/mt/maven-web-application/0.0.4-SNAPSHOT/maven-web-application-0.0.4-SNAPSHOT.pom


http://mymumbai-nlb-9e84f36787a935a1.elb.ap-south-1.amazonaws.com/maven-web-application/


Press the Windows key.
Type Notepad in the search field.
In the search results, right-click Notepad and select Run as administrator.
From Notepad, open the following file: c:\Windows\System32\Drivers\etc\hosts.
Make the necessary changes to the file.


nslookup  mymumbai-nlb-9e84f36787a935a1.elb.ap-south-1.amazonaws.com

 http://mymumbai-nlb-9e84f36787a935a1.elb.ap-south-1.amazonaws.com/maven-web-application/

take ip here

52.66.132.194 raithadinachari.com

Select File > Save to save your changes.



raithadinachari.com/maven-web-application/
                     -->> DNS -- IP  --Public ip
                                                        ------Load Balancer --to private Ip
														--------Application server

http://mavenwebapp.mithuntechdevops.co.in/maven-web-application


http://javawebapp.mithuntechdevops.co.in/java-web-app

-------------------------

NLB-Java-web-app-8e438c6202429203.elb.ap-south-1.amazonaws.com/java-web/

http://nlb-java-web-app-8e438c6202429203.elb.ap-south-1.amazonaws.com/java-web/

raithadinachari.nat.com/java-web/



Application LB:


http://applb-433928400.ap-south-1.elb.amazonaws.com/maven-web-application

http://applb-2037253127.ap-south-1.elb.amazonaws.com/java-web/



http://mithuntechdevops.co.in/java-web-app/

http://mithuntechdevops.co.in/maven-web-application/

--ALLB domain

http://raithadinachari.ckm.com/maven-web-application/ 

http://raithadinachari.ckm.com/java-web


52.66.132.194 raithadinachari.com #maven NLB
3.109.253.62 raithadinachari.nat.com #java NLB
13.232.84.106 raithadinachari.ckm.com # Maven , Java APPLB


CLI:

https://awscli.amazonaws.com/AWSCLIV2.msi



What is IAM?
--------------------
•	IAM allows you to manage users and their level of access to the AWS Console.
•	IAM user limit is 5000 per AWS account and at a time you can add 10 Users.
•	1000 IAM roles are limited in one account
•	IAM User can be a member of 10 groups
•	Maximum 2 access key can provide to one User.
•	Permission is assigned to any IAM users by the JSON Policies.

•	Programmatically access (access key and secret access key) – service user to access any service
•	Interactive login access (user and password) – AWS mgmt. Console login access
 

Identity Access Management (IAM) offers the following features:-
-------------------------------------------------------------------------------------------
•	Centralized control of your AWS account
•	Shared Access to your AWS account 
•	Granular Permissions
•	Identity Federation (including Active Directory, Facebook, Linkedin etc.)
•	Multifactor Authentication
•	Provide temporary access for users/devices and services where necessary
•	Allows you to set up your own password rotation policy
•	Integrates with many different AWS services
•	Supports PCI DSS Compliance
•	 Your whole AWS security is there:
•	Users
•	Groups
•	Roles
•	Policies
•	Root account should never be used (and shared)
•	Users must be created with proper permissions
•	IAM is at the center of AWS
•	Policies are written in JSON (JavaScript Object Notation)
•	IAM has a global view
•	Permissions are governed by Policies (JSON)
•	MFA (Multi Factor Authentication) can be setup
•	IAM has predefined “managed policies”
•	It’s best to give users the minimal amount of
•	Big enterprises usually integrate their own repository of users with IAM
•	This way, one can login into AWS using their company credentials
•	Identity Federation uses the SAML standard (Active Directory)

Users: - End Users such as people, employees of an organization etc.

Groups: - A collection of users. Each user in the group will inherit the permission of the group.

Policies: - Policies are made up of documents. These documents are in a format called JSON and they give permission as to what a User/Group Role is able to do.

Roles: - You create roles and then assign them to AWS Resources.
Roles is the way by which you can use one AWS service to another AWS service. 
Example that if you want to give access to any EC2 instance to any S3 bucket.




Tips:-
----------
•	IAM is universal. It does not apply to regions at this time.
•	The "root account" is simply the account created when first setup your AWS account. It has complete Admin access.
•	New Users have NO permissions when first created.
•	New Users are assigned Access Key ID & Secret Access Keys when first created.
•	These are not the same as a password. You cannot use the Access key ID & Secret Access Key to Login in to the console. You can use this to access AWS via the APIs and command line, however.
•	You only get to view these once. If you lose them, you have to regenerate them. So, save them in a secure location. 
•	Always setup Multifactor Authentication on your root account.
•	You can create and customize your own password rotation policies.
•	One IAM User per PHYSICAL PERSON
•	One IAM Role per Application
•	IAM credentials should NEVER BE SHARED
•	Never, ever, ever, ever, write IAM credentials in code. EVER.
•	And even less, NEVER EVER EVER COMMIT YOUR IAM credentials
•	Never use the ROOT account except for initial setup.
•	Never use ROOT IAM Credentials


users

harish
mithun 

Pwsd:
H@r!$h12341

bhaskar:
H@r!$h1234





------
